<!DOCTYPE html>
<html lang="en">

<head><script src="/livereload.js?mindelay=10&amp;v=2&amp;port=1313&amp;path=livereload" data-no-instant defer></script>
  <title>
  Retrieval Augmented Generation On JFK Speeches: Part 1 · Mike Harmon
</title>
  <meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<meta name="color-scheme" content="light dark">




<meta name="author" content="Mike Harmon">
<meta name="description" content="
  Contents
  
    
    Link to heading
  

1. Introduction
2. Scraping JFK Speeches using Asyncio
3. Loading and Embedding Speeches
4. Ingesting Speeches Into A Pinecone Vector Database 
5. Next Steps

  1. Introduction 
  
    
    Link to heading
  


In this post I venture into building a Retrieval Augumented Generation (RAG) application that has been &ldquo;trained&rdquo; on President John F. Kennedy speeches. In past posts I covered how I collected JFK speeches and built a &ldquo;speech writer&rdquo; using a Gated Recurrent Unit (GRU) Neural Network. In this post I improve upon on the prior work to build a RAG pipeline.">
<meta name="keywords" content="blog,data,ai">



  <meta name="twitter:card" content="summary">
  <meta name="twitter:title" content="Retrieval Augmented Generation On JFK Speeches: Part 1">
  <meta name="twitter:description" content="Contents Link to heading 1. Introduction
2. Scraping JFK Speeches using Asyncio
3. Loading and Embedding Speeches
4. Ingesting Speeches Into A Pinecone Vector Database 5. Next Steps
1. Introduction Link to heading In this post I venture into building a Retrieval Augumented Generation (RAG) application that has been “trained” on President John F. Kennedy speeches. In past posts I covered how I collected JFK speeches and built a “speech writer” using a Gated Recurrent Unit (GRU) Neural Network. In this post I improve upon on the prior work to build a RAG pipeline.">

<meta property="og:url" content="http://localhost:1313/posts/rag_jfk1/">
  <meta property="og:site_name" content="Mike Harmon">
  <meta property="og:title" content="Retrieval Augmented Generation On JFK Speeches: Part 1">
  <meta property="og:description" content="Contents Link to heading 1. Introduction
2. Scraping JFK Speeches using Asyncio
3. Loading and Embedding Speeches
4. Ingesting Speeches Into A Pinecone Vector Database 5. Next Steps
1. Introduction Link to heading In this post I venture into building a Retrieval Augumented Generation (RAG) application that has been “trained” on President John F. Kennedy speeches. In past posts I covered how I collected JFK speeches and built a “speech writer” using a Gated Recurrent Unit (GRU) Neural Network. In this post I improve upon on the prior work to build a RAG pipeline.">
  <meta property="og:locale" content="en">
  <meta property="og:type" content="article">
    <meta property="article:section" content="posts">
    <meta property="article:published_time" content="2025-03-13T00:00:00+00:00">
    <meta property="article:modified_time" content="2025-03-13T00:00:00+00:00">
    <meta property="article:tag" content="Asyncio">
    <meta property="article:tag" content="LangChain">
    <meta property="article:tag" content="Pinecone">
      <meta property="og:see_also" content="http://localhost:1313/posts/rag_jfk2/">
      <meta property="og:see_also" content="http://localhost:1313/posts/chatbot2/">
      <meta property="og:see_also" content="http://localhost:1313/posts/chatbot1/">




<link rel="canonical" href="http://localhost:1313/posts/rag_jfk1/">


<link rel="preload" href="/fonts/fa-brands-400.woff2" as="font" type="font/woff2" crossorigin>
<link rel="preload" href="/fonts/fa-regular-400.woff2" as="font" type="font/woff2" crossorigin>
<link rel="preload" href="/fonts/fa-solid-900.woff2" as="font" type="font/woff2" crossorigin>


  
  
  <link rel="stylesheet" href="/css/coder.css" media="screen">






  
    
    
    <link rel="stylesheet" href="/css/coder-dark.css" media="screen">
  



 


  
  
    
    
    <link rel="stylesheet" href="/scss/coder.css" media="screen">
  

  
  
    
    
    <link rel="stylesheet" href="/scss/coder-dark.css" media="screen">
  



<link rel="icon" type="image/svg+xml" href="/images/favicon.svg" sizes="any">
<link rel="icon" type="image/png" href="/images/favicon-32x32.png" sizes="32x32">
<link rel="icon" type="image/png" href="/images/favicon-16x16.png" sizes="16x16">

<link rel="apple-touch-icon" href="/images/apple-touch-icon.png">
<link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon.png">

<link rel="manifest" href="/site.webmanifest">
<link rel="mask-icon" href="/images/safari-pinned-tab.svg" color="#5bbad5">









</head>






<body class="preload-transitions colorscheme-auto">
  
<div class="float-container">
    <a id="dark-mode-toggle" class="colorscheme-toggle">
        <i class="fa-solid fa-adjust fa-fw" aria-hidden="true"></i>
    </a>
</div>


  <main class="wrapper">
    <nav class="navigation">
  <section class="container">
    
    <a class="navigation-title" href="http://localhost:1313/">
      Mike Harmon
    </a>
    
    
      <input type="checkbox" id="menu-toggle" />
      <label class="menu-button float-right" for="menu-toggle">
        <i class="fa-solid fa-bars fa-fw" aria-hidden="true"></i>
      </label>
      <ul class="navigation-list">
        
          
            <li class="navigation-item">
              <a class="navigation-link " href="/about">About</a>
            </li>
          
            <li class="navigation-item">
              <a class="navigation-link " href="/posts/">Blog</a>
            </li>
          
            <li class="navigation-item">
              <a class="navigation-link " href="/projects/">Projects</a>
            </li>
          
            <li class="navigation-item">
              <a class="navigation-link " href="/contact/">Contact me</a>
            </li>
          
        
        
      </ul>
    
  </section>
</nav>


    <div class="content">
      
  <section class="container post">
    <article>
      <header>
        <div class="post-title">
          <h1 class="title">
            <a class="title-link" href="http://localhost:1313/posts/rag_jfk1/">
              Retrieval Augmented Generation On JFK Speeches: Part 1
            </a>
          </h1>
        </div>
        <div class="post-meta">
          <div class="date">
            <span class="posted-on">
              <i class="fa-solid fa-calendar" aria-hidden="true"></i>
              <time datetime="2025-03-13T00:00:00Z">
                March 13, 2025
              </time>
            </span>
            <span class="reading-time">
              <i class="fa-solid fa-clock" aria-hidden="true"></i>
              15-minute read
            </span>
          </div>
          <div class="authors">
  <i class="fa-solid fa-user" aria-hidden="true"></i>
    <a href="/authors/mike-harmon/">Mike Harmon</a></div>

          
          <div class="tags">
  <i class="fa-solid fa-tag" aria-hidden="true"></i>
    <span class="tag">
      <a href="/tags/asyncio/">Asyncio</a>
    </span>
      <span class="separator">•</span>
    <span class="tag">
      <a href="/tags/langchain/">LangChain</a>
    </span>
      <span class="separator">•</span>
    <span class="tag">
      <a href="/tags/pinecone/">Pinecone</a>
    </span></div>

        </div>
      </header>

      <div class="post-content">
        
        <h3 id="contents">
  Contents
  <a class="heading-link" href="#contents">
    <i class="fa-solid fa-link" aria-hidden="true" title="Link to heading"></i>
    <span class="sr-only">Link to heading</span>
  </a>
</h3>
<p><strong><a href="#first-bullet" >1. Introduction</a></strong></p>
<p><strong><a href="#second-bullet" >2. Scraping JFK Speeches using Asyncio</a></strong></p>
<p><strong><a href="#third-bullet" >3. Loading and Embedding Speeches</a></strong></p>
<p><strong><a href="#fourth-bullet" >4. Ingesting Speeches Into A Pinecone Vector Database </a></strong></p>
<p><strong><a href="#fifth-bullet" >5. Next Steps</a></strong></p>
<h3 id="1-introduction">
  1. Introduction <a class="anchor" id="first-bullet"></a>
  <a class="heading-link" href="#1-introduction">
    <i class="fa-solid fa-link" aria-hidden="true" title="Link to heading"></i>
    <span class="sr-only">Link to heading</span>
  </a>
</h3>
<hr>
<p>In this post I venture into building a Retrieval Augumented Generation (RAG) application that has been &ldquo;trained&rdquo; on President John F. Kennedy speeches. In past posts I covered how I <a href="http://michael-harmon.com/blog/jfk1.html"  class="external-link" target="_blank" rel="noopener">collected JFK speeches</a> and <a href="http://michael-harmon.com/blog/jfk2.html"  class="external-link" target="_blank" rel="noopener">built a &ldquo;speech writer&rdquo;</a> using a <a href="https://en.wikipedia.org/wiki/Gated_recurrent_unit"  class="external-link" target="_blank" rel="noopener">Gated Recurrent Unit (GRU) Neural Network</a>. In this post I improve upon on the prior work to build a RAG pipeline.</p>
<p>The first thing I will cover is how I collected the data to include extra metadata on speeches as well as using the <a href="https://docs.python.org/3/library/asyncio.html"  class="external-link" target="_blank" rel="noopener">Asyncio</a> package to reduce run time when writing to object storage. Next, I will go over how to load the json files from <a href="https://cloud.google.com/storage?hl=en"  class="external-link" target="_blank" rel="noopener">Google Cloud Storage</a> using different <a href="https://www.langchain.com/"  class="external-link" target="_blank" rel="noopener">LangChain</a> loaders. After that I cover how to embed documents and ingest the data into a <a href="https://pinecone.io/"  class="external-link" target="_blank" rel="noopener">Pinecone Vector Database</a>. In a follow up post I&rsquo;ll cover how to create and deploy the actual RAG application.</p>
<p>Now I&rsquo;ll import all the classes and functions I will need for the rest of the post.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#75715e"># LangChain</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">from</span> langchain_google_community.gcs_file <span style="color:#f92672">import</span> GCSFileLoader
</span></span><span style="display:flex;"><span><span style="color:#f92672">from</span> langchain_google_community.gcs_directory <span style="color:#f92672">import</span> GCSDirectoryLoader
</span></span><span style="display:flex;"><span><span style="color:#f92672">from</span> langchain.document_loaders <span style="color:#f92672">import</span> JSONLoader
</span></span><span style="display:flex;"><span><span style="color:#f92672">from</span> langchain.text_splitter <span style="color:#f92672">import</span> RecursiveCharacterTextSplitter
</span></span><span style="display:flex;"><span><span style="color:#f92672">from</span> langchain_nvidia_ai_endpoints <span style="color:#f92672">import</span> NVIDIAEmbeddings
</span></span><span style="display:flex;"><span><span style="color:#f92672">from</span> langchain_pinecone.vectorstores <span style="color:#f92672">import</span> PineconeVectorStore
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Google Cloud</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">import</span> os
</span></span><span style="display:flex;"><span><span style="color:#f92672">from</span> google.cloud <span style="color:#f92672">import</span> storage
</span></span><span style="display:flex;"><span><span style="color:#f92672">from</span> google.oauth2 <span style="color:#f92672">import</span> service_account
</span></span><span style="display:flex;"><span>credentials <span style="color:#f92672">=</span> service_account<span style="color:#f92672">.</span>Credentials<span style="color:#f92672">.</span>from_service_account_file(<span style="color:#e6db74">&#39;../credentials.json&#39;</span>)
</span></span><span style="display:flex;"><span>os<span style="color:#f92672">.</span>environ[<span style="color:#e6db74">&#34;GOOGLE_APPLICATION_CREDENTIALS&#34;</span>] <span style="color:#f92672">=</span> <span style="color:#e6db74">&#34;../credentials.json&#34;</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Pinecone VectorDB</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">from</span> pinecone <span style="color:#f92672">import</span> Pinecone
</span></span><span style="display:flex;"><span><span style="color:#f92672">from</span> pinecone <span style="color:#f92672">import</span> ServerlessSpec
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># API Keys</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">from</span> dotenv <span style="color:#f92672">import</span> load_dotenv
</span></span><span style="display:flex;"><span>load_dotenv()
</span></span></code></pre></div><pre><code>True
</code></pre>
<h3 id="2-scraping-jfk-speeches-using-asyncio">
  2. Scraping JFK Speeches using Asyncio <a class="anchor" id="second-bullet"></a>
  <a class="heading-link" href="#2-scraping-jfk-speeches-using-asyncio">
    <i class="fa-solid fa-link" aria-hidden="true" title="Link to heading"></i>
    <span class="sr-only">Link to heading</span>
  </a>
</h3>
<hr>
<p>In the <a href="http://michael-harmon.com/blog/jfk1.html"  class="external-link" target="_blank" rel="noopener">first post</a> of my work on a speecher writer I covered how to injest the JFK speeches from his <a href="https://www.jfklibrary.org/archives/other-resources/john-f-kennedy-speeches"  class="external-link" target="_blank" rel="noopener">presidential library</a> into <a href="https://cloud.google.com/storage?hl=en"  class="external-link" target="_blank" rel="noopener">Google Cloud Storage</a>. I was never completely satisfied with the way I wrote the job before and  decided to go back and redo it using the <a href="https://docs.python.org/3/library/asyncio.html"  class="external-link" target="_blank" rel="noopener">Asyncio</a> library to perform Asynchronous reading of HTML and writing json to Google cloud storage. The json documents include the text of the speech, its title, source and url for the speech. I don&rsquo;t want to go into the details this work, but I will say it was not as hard as I would have thought! The main thing was to turn functions which use the request package into <a href="https://docs.python.org/3/library/asyncio-task.html#coroutines"  class="external-link" target="_blank" rel="noopener">coroutines</a>. Informally, when using <code>requests.get</code> method to scrape the scrape a website, query a REST API or other I/O methods the process is &ldquo;blocking&rdquo;. This means the Python task is not able to proceed until its receives the return value (or hears back) from the API or website. In the time the program is waiting, the threads and CPU could be doing other work. The <a href="https://docs.python.org/3/library/asyncio.html"  class="external-link" target="_blank" rel="noopener">Asyncio</a> library allows Python to to free up these idling threads to do other work while waiting for I/O work to complete.</p>
<p>If you are interested in reading more about it the script is <a href="https://github.com/mdh266/rag-jfk/blob/main/scripts/extract.py"  class="external-link" target="_blank" rel="noopener">here</a>.</p>
<h3 id="3-loading-and-embedding-speeches">
  3. Loading and Embedding Speeches <a class="anchor" id="third-bullet"></a>
  <a class="heading-link" href="#3-loading-and-embedding-speeches">
    <i class="fa-solid fa-link" aria-hidden="true" title="Link to heading"></i>
    <span class="sr-only">Link to heading</span>
  </a>
</h3>
<hr>
<p>At this point I have run the <a href="https://github.com/mdh266/rag-jfk/blob/main/scripts/extract.py"  class="external-link" target="_blank" rel="noopener">extract.py</a> script which scraped the JFK libary website and converted the speeches into json. The speeches exist as json documents in <a href="https://cloud.google.com/storage?hl=en"  class="external-link" target="_blank" rel="noopener">Google Cloud Storage</a> and in order to ingest it into <a href="https://pinecone.io/"  class="external-link" target="_blank" rel="noopener">Pinecone</a> requires the use of the <a href="https://python.langchain.com/docs/integrations/document_loaders/json/"  class="external-link" target="_blank" rel="noopener">JSONLoader</a> function from <a href="https://www.langchain.com/"  class="external-link" target="_blank" rel="noopener">LangChain</a>. In addition to loading the documents I also wanted to add metadata to the documents. I did so using LangChain by creating the <code>metadata_func</code> below:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#f92672">from</span> typing <span style="color:#f92672">import</span> Dict
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">def</span> <span style="color:#a6e22e">metadata_func</span>(record: Dict[str, str], metadata: Dict[str, str]) <span style="color:#f92672">-&gt;</span> Dict[str, str]:
</span></span><span style="display:flex;"><span>    metadata[<span style="color:#e6db74">&#34;title&#34;</span>] <span style="color:#f92672">=</span> record<span style="color:#f92672">.</span>get(<span style="color:#e6db74">&#34;title&#34;</span>)
</span></span><span style="display:flex;"><span>    metadata[<span style="color:#e6db74">&#34;source&#34;</span>] <span style="color:#f92672">=</span> record<span style="color:#f92672">.</span>get(<span style="color:#e6db74">&#34;source&#34;</span>)
</span></span><span style="display:flex;"><span>    metadata[<span style="color:#e6db74">&#34;url&#34;</span>] <span style="color:#f92672">=</span> record<span style="color:#f92672">.</span>get(<span style="color:#e6db74">&#34;url&#34;</span>)
</span></span><span style="display:flex;"><span>    metadata[<span style="color:#e6db74">&#34;filename&#34;</span>] <span style="color:#f92672">=</span> record<span style="color:#f92672">.</span>get(<span style="color:#e6db74">&#34;filename&#34;</span>)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">return</span> metadata
</span></span></code></pre></div><p>I put this function to use by instantiating the object and passing it as the <code>metadata_func</code> parameter,</p>
<pre><code>loader = JSONLoader(
            file_path, 
            jq_schema=jq_schema, 
            text_content=False,
            content_key=&quot;text&quot;,
            metadata_func=metadata_func
)
</code></pre>
<p>However, I would only be able to use the <code>loader</code> object on local json document with a path (<code>file_path</code>) on my file system.</p>
<p>In order to use this function to load json from a GCP bucket I need to create a function that takes in a file and its path (<code>file_path</code>) as well as the function to process the metadata about the speech&rsquo;s name, where it came from and return an instantiated <code>JSONLoader</code> object to read the file:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span>    
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">def</span> <span style="color:#a6e22e">load_json</span>(file_path: str, jq_schema: str<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;.&#34;</span>):
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">return</span> JSONLoader(
</span></span><span style="display:flex;"><span>                file_path, 
</span></span><span style="display:flex;"><span>                jq_schema<span style="color:#f92672">=</span>jq_schema, 
</span></span><span style="display:flex;"><span>                text_content<span style="color:#f92672">=</span><span style="color:#66d9ef">False</span>,
</span></span><span style="display:flex;"><span>                content_key<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;text&#34;</span>,
</span></span><span style="display:flex;"><span>                metadata_func<span style="color:#f92672">=</span>metadata_func
</span></span><span style="display:flex;"><span>)
</span></span></code></pre></div><p>Now I can pass this function to the LangChain&rsquo;s <a href="https://python.langchain.com/api_reference/community/document_loaders/langchain_community.document_loaders.gcs_file.GCSFileLoader.html"  class="external-link" target="_blank" rel="noopener">GCFSFileLoader</a>. I can then instantiate the class to load file the first debate between Kennedy and Nixon from my GCP bucket. The full path for this json document is,</p>
<pre><code>gs://kennedyskis/1st-nixon-kennedy-debate-19600926.json
</code></pre>
<p>The code to load the json document is,</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span>loader <span style="color:#f92672">=</span> GCSFileLoader(project_name<span style="color:#f92672">=</span>credentials<span style="color:#f92672">.</span>project_id,
</span></span><span style="display:flex;"><span>                       bucket<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;kennedyskis&#34;</span>,
</span></span><span style="display:flex;"><span>                       blob<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;1st-nixon-kennedy-debate-19600926.json&#34;</span>,
</span></span><span style="display:flex;"><span>                       loader_func<span style="color:#f92672">=</span>load_json)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>document <span style="color:#f92672">=</span> loader<span style="color:#f92672">.</span>load()
</span></span></code></pre></div><p>This will return a list of <a href="https://python.langchain.com/api_reference/core/documents/langchain_core.documents.base.Document.html"  class="external-link" target="_blank" rel="noopener">LangChain Document(s)</a>. The text of the debate can be seen using the <code>.page_content</code> attribute,</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span>print(document[<span style="color:#ae81ff">0</span>]<span style="color:#f92672">.</span>page_content[:<span style="color:#ae81ff">1000</span>])
</span></span></code></pre></div><pre><code>[Text, format, and style are as published in Freedom of Communications: Final Report of the Committee on Commerce, United States Senate..., Part III: The Joint Appearances of Senator John F. Kennedy and Vice President Richard M. Nixon and Other 1960 Campaign Presentations. 87th Congress, 1st Session, Senate Report No. 994, Part 3. Washington: U.S. Government Printing Office, 1961.]
Monday, September 26, 1960
Originating CBS, Chicago, Ill., All Networks carried.
Moderator, Howard K. Smith.
MR. SMITH: Good evening.
The television and radio stations of the United States and their affiliated stations are proud to provide facilities for a discussion of issues in the current political campaign by the two major candidates for the presidency.
The candidates need no introduction. The Republican candidate, Vice President Richard M. Nixon, and the Democratic candidate, Senator John F. Kennedy.
According to rules set by the candidates themselves, each man shall make an opening statement of approx
</code></pre>
<p>The metadata for the document can be seen from the <code>.metadata</code> attribute,</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span>document[<span style="color:#ae81ff">0</span>]<span style="color:#f92672">.</span>metadata
</span></span></code></pre></div><pre><code>{'source': 'gs://kennedyskis/1st-nixon-kennedy-debate-19600926.json',
 'seq_num': 1,
 'title': 'Senator John F. Kennedy and Vice President Richard M. Nixon First Joint Radio-Television Broadcast, September 26, 1960',
 'url': 'https://www.jfklibrary.org//archives/other-resources/john-f-kennedy-speeches/1st-nixon-kennedy-debate-19600926',
 'filename': '1st-nixon-kennedy-debate-19600926'}
</code></pre>
<p>This debate document (and documents in generally) usually are too long to fit in the context window of an LLM so we need to break them up into smaller pieces of texts. This process is called &ldquo;chunking&rdquo;. Below I will show how to break up the Nixon-Kennedy debate into &ldquo;chunks&rdquo; of 200 characters with 20 characters that overlap between chunks. I do this using the <a href="https://python.langchain.com/api_reference/text_splitters/character/langchain_text_splitters.character.RecursiveCharacterTextSplitter.html"  class="external-link" target="_blank" rel="noopener">RecursiveCharacterTextSplitter</a> class as shown below,</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span>text_splitter <span style="color:#f92672">=</span> RecursiveCharacterTextSplitter(chunk_size<span style="color:#f92672">=</span><span style="color:#ae81ff">200</span>, chunk_overlap<span style="color:#f92672">=</span><span style="color:#ae81ff">20</span>)
</span></span><span style="display:flex;"><span>documents <span style="color:#f92672">=</span> text_splitter<span style="color:#f92672">.</span>split_documents(document)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>print(<span style="color:#e6db74">&#34;Number of documents: &#34;</span>, len(documents))
</span></span></code></pre></div><pre><code>Number of documents:  429
</code></pre>
<p>Now we can look at the documents and their associated metadata,</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#66d9ef">for</span> n, doc <span style="color:#f92672">in</span> enumerate(documents[:<span style="color:#ae81ff">3</span>]):
</span></span><span style="display:flex;"><span>    print(<span style="color:#e6db74">f</span><span style="color:#e6db74">&#34;Doc </span><span style="color:#e6db74">{</span>n<span style="color:#e6db74">}</span><span style="color:#e6db74">: &#34;</span>, doc<span style="color:#f92672">.</span>page_content, <span style="color:#e6db74">&#34;</span><span style="color:#ae81ff">\n</span><span style="color:#e6db74">&#34;</span>, <span style="color:#e6db74">&#34;</span><span style="color:#ae81ff">\t</span><span style="color:#e6db74">Metadata:&#34;</span>, doc<span style="color:#f92672">.</span>metadata, <span style="color:#e6db74">&#34;</span><span style="color:#ae81ff">\n</span><span style="color:#e6db74">&#34;</span>)
</span></span></code></pre></div><pre><code>Doc 0:  [Text, format, and style are as published in Freedom of Communications: Final Report of the Committee on Commerce, United States Senate..., Part III: The Joint Appearances of Senator John F. Kennedy 
 	Metadata: {'source': 'gs://kennedyskis/1st-nixon-kennedy-debate-19600926.json', 'seq_num': 1, 'title': 'Senator John F. Kennedy and Vice President Richard M. Nixon First Joint Radio-Television Broadcast, September 26, 1960', 'url': 'https://www.jfklibrary.org//archives/other-resources/john-f-kennedy-speeches/1st-nixon-kennedy-debate-19600926', 'filename': '1st-nixon-kennedy-debate-19600926'} 

Doc 1:  John F. Kennedy and Vice President Richard M. Nixon and Other 1960 Campaign Presentations. 87th Congress, 1st Session, Senate Report No. 994, Part 3. Washington: U.S. Government Printing Office, 
 	Metadata: {'source': 'gs://kennedyskis/1st-nixon-kennedy-debate-19600926.json', 'seq_num': 1, 'title': 'Senator John F. Kennedy and Vice President Richard M. Nixon First Joint Radio-Television Broadcast, September 26, 1960', 'url': 'https://www.jfklibrary.org//archives/other-resources/john-f-kennedy-speeches/1st-nixon-kennedy-debate-19600926', 'filename': '1st-nixon-kennedy-debate-19600926'} 

Doc 2:  Printing Office, 1961.] 
 	Metadata: {'source': 'gs://kennedyskis/1st-nixon-kennedy-debate-19600926.json', 'seq_num': 1, 'title': 'Senator John F. Kennedy and Vice President Richard M. Nixon First Joint Radio-Television Broadcast, September 26, 1960', 'url': 'https://www.jfklibrary.org//archives/other-resources/john-f-kennedy-speeches/1st-nixon-kennedy-debate-19600926', 'filename': '1st-nixon-kennedy-debate-19600926'} 
</code></pre>
<p>Notice the metadata is the same for each of the documents since they all come from the same original json file.</p>
<p>Now that we have data that is loaded, well go over how to use <a href="https://platform.openai.com/docs/guides/embeddings"  class="external-link" target="_blank" rel="noopener">embeddings</a> to convert the text into vectors. I have covered embeddings in <a href="http://michael-harmon.com/blog/jfk2.html"  class="external-link" target="_blank" rel="noopener">prior posts</a>, so I won&rsquo;t go over it in much detail here. Instead I will focus on the LangChain commands needed to use embeddings. We can instantiate the LangChain <a href="https://python.langchain.com/api_reference/nvidia_ai_endpoints/embeddings/langchain_nvidia_ai_endpoints.embeddings.NVIDIAEmbeddings.html/"  class="external-link" target="_blank" rel="noopener">NVIDIAEmbeddings</a> class, which uses <a href="https://build.nvidia.com/nvidia/llama-3_2-nv-embedqa-1b-v2"  class="external-link" target="_blank" rel="noopener">Nvidia&rsquo;s Llama 3.2 embeddings</a>, and then use the <a href="https://python.langchain.com/docs/integrations/text_embedding/openai/#direct-usage"  class="external-link" target="_blank" rel="noopener">embed_query</a> method to embed a single document as shown:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span>embedding <span style="color:#f92672">=</span> embedding <span style="color:#f92672">=</span> NVIDIAEmbeddings(
</span></span><span style="display:flex;"><span>                            model<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;nvidia/llama-3.2-nv-embedqa-1b-v2&#34;</span>,
</span></span><span style="display:flex;"><span>                            api_key<span style="color:#f92672">=</span>os<span style="color:#f92672">.</span>getenv(<span style="color:#e6db74">&#34;NVIDIA_API_KEY&#34;</span>),
</span></span><span style="display:flex;"><span>                            dimension<span style="color:#f92672">=</span><span style="color:#ae81ff">2048</span>,
</span></span><span style="display:flex;"><span>                            truncate<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;NONE&#34;</span>)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>query <span style="color:#f92672">=</span> embedding<span style="color:#f92672">.</span>embed_query(documents[<span style="color:#ae81ff">0</span>]<span style="color:#f92672">.</span>page_content)
</span></span></code></pre></div><p>Now we can see the first 5 entries of the vector,</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span>print(<span style="color:#e6db74">&#34;First 5 entries in embedded document:&#34;</span>, query[:<span style="color:#ae81ff">5</span>])
</span></span></code></pre></div><pre><code>First 5 entries in embedded document: [-0.00730133056640625, 0.01448822021484375, 0.01450347900390625, 0.00974273681640625, 0.0265350341796875]
</code></pre>
<p>As well as the size of the vector:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span>print(<span style="color:#e6db74">&#34;Vector size:&#34;</span>, len(query))
</span></span></code></pre></div><pre><code>Vector size: 2048
</code></pre>
<p>The embedding of text is important for the retrivial process of RAG. We embed all our documents and then embed our question and use the embeddings help to perform <a href="https://www.elastic.co/what-is/semantic-search"  class="external-link" target="_blank" rel="noopener">semantic search</a> which will improve the results of our search. I&rsquo;&rsquo;ll touch on this a little more towards the end of this blog post.</p>
<h3 id="4-ingesting-speeches-into-a-pinecone-vector-database">
  4. Ingesting Speeches Into A Pinecone Vector Database <a class="anchor" id="fourth-bullet"></a>
  <a class="heading-link" href="#4-ingesting-speeches-into-a-pinecone-vector-database">
    <i class="fa-solid fa-link" aria-hidden="true" title="Link to heading"></i>
    <span class="sr-only">Link to heading</span>
  </a>
</h3>
<hr>
<p>Now we can load all of President Kennedys speeches using a <a href="https://python.langchain.com/docs/integrations/document_loaders/google_cloud_storage_directory/"  class="external-link" target="_blank" rel="noopener">GCSDirectoryLoader</a> which loads an entire directoy in a bucket instead of just a single file. I can see the speeches of his presidency by getting the bucket and loading all the names of the speeches:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span>client <span style="color:#f92672">=</span> storage<span style="color:#f92672">.</span>Client(project<span style="color:#f92672">=</span>credentials<span style="color:#f92672">.</span>project_id,
</span></span><span style="display:flex;"><span>                        credentials<span style="color:#f92672">=</span>credentials)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>bucket <span style="color:#f92672">=</span> client<span style="color:#f92672">.</span>get_bucket(<span style="color:#e6db74">&#34;prezkennedyspeches&#34;</span>)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>speeches <span style="color:#f92672">=</span> [blob<span style="color:#f92672">.</span>name <span style="color:#66d9ef">for</span> blob <span style="color:#f92672">in</span> bucket<span style="color:#f92672">.</span>list_blobs()]
</span></span><span style="display:flex;"><span>print(<span style="color:#e6db74">f</span><span style="color:#e6db74">&#34;JFK had </span><span style="color:#e6db74">{</span>len(speeches)<span style="color:#e6db74">}</span><span style="color:#e6db74"> speeches in his presidency.&#34;</span>)
</span></span></code></pre></div><pre><code>JFK had 22 speeches in his presidency.
</code></pre>
<p>The speeches are:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span>speeches
</span></span></code></pre></div><pre><code>['american-newspaper-publishers-association-19610427.json',
 'american-society-of-newspaper-editors-19610420.json',
 'american-university-19630610.json',
 'americas-cup-dinner-19620914.json',
 'berlin-crisis-19610725.json',
 'berlin-w-germany-rudolph-wilde-platz-19630626.json',
 'civil-rights-radio-and-television-report-19630611.json',
 'cuba-radio-and-television-report-19621022.json',
 'inaugural-address-19610120.json',
 'inaugural-anniversary-19620120.json',
 'irish-parliament-19630628.json',
 'latin-american-diplomats-washington-dc-19610313.json',
 'massachusetts-general-court-19610109.json',
 'peace-corps-establishment-19610301.json',
 'philadelphia-pa-19620704.json',
 'rice-university-19620912.json',
 'united-nations-19610925.json',
 'united-states-congress-special-message-19610525.json',
 'university-of-california-berkeley-19620323.json',
 'university-of-mississippi-19620930.json',
 'vanderbilt-university-19630518.json',
 'yale-university-19620611.json']
</code></pre>
<p>Next I load all of the speeches using the <a href="https://python.langchain.com/docs/integrations/document_loaders/google_cloud_storage_directory/"  class="external-link" target="_blank" rel="noopener">GCSDirectoryLoader</a> and split them into chunks of size 2,000 characters with 100 characters overlapping using the<code>load_and_split</code> method:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span>loader <span style="color:#f92672">=</span> GCSDirectoryLoader(
</span></span><span style="display:flex;"><span>                project_name<span style="color:#f92672">=</span>credentials<span style="color:#f92672">.</span>project_id,
</span></span><span style="display:flex;"><span>                bucket<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;prezkennedyspeches&#34;</span>,
</span></span><span style="display:flex;"><span>                loader_func<span style="color:#f92672">=</span>load_json
</span></span><span style="display:flex;"><span>)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>text_splitter <span style="color:#f92672">=</span> RecursiveCharacterTextSplitter(chunk_size<span style="color:#f92672">=</span><span style="color:#ae81ff">2000</span>, chunk_overlap<span style="color:#f92672">=</span><span style="color:#ae81ff">100</span>)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>documents <span style="color:#f92672">=</span> loader<span style="color:#f92672">.</span>load_and_split(text_splitter)
</span></span><span style="display:flex;"><span>print(<span style="color:#e6db74">f</span><span style="color:#e6db74">&#34;There are </span><span style="color:#e6db74">{</span>len(documents)<span style="color:#e6db74">}</span><span style="color:#e6db74"> documents&#34;</span>)
</span></span></code></pre></div><pre><code>There are 180 documents
</code></pre>
<p>Now we&rsquo;re ready to connect to Pinecone and ingest the data into the vector database. I can create the connection to Pinecone using the command,</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span>pc <span style="color:#f92672">=</span> Pinecone(api_key<span style="color:#f92672">=</span>os<span style="color:#f92672">.</span>getenv(<span style="color:#e6db74">&#34;PINECONE_API_KEY&#34;</span>))
</span></span></code></pre></div><p>I&rsquo;ll create an index in Pinecone to store the documents. An index is basically a collection of embedded documents, similar to a table in a traditional database. <a href="https://en.wikipedia.org/wiki/Vector_database"  class="external-link" target="_blank" rel="noopener">Vector databases</a> are specialized databases that allow for storage of vectors as well as for fast searches and retrivials. The vectors have numerical values and represents the documents in embedded form. The vectors are usually high dimensional (in our case 1,536 dimensions) and dense. However, compared to <a href="http://michael-harmon.com/blog/NLP1.html"  class="external-link" target="_blank" rel="noopener">other representations of text</a> such as the <a href="https://en.wikipedia.org/wiki/Bag-of-words_model"  class="external-link" target="_blank" rel="noopener">Bag-Of-Words model</a> embedding vectors are relatively low dimensional. There are many benefits of vector embeddings and one of the most important is the ability to measure <a href="https://en.wikipedia.org/wiki/Semantic_similarity#:~:text=Semantic%20similarity%20is%20a%20metric,as%20opposed%20to%20lexicographical%20similarity."  class="external-link" target="_blank" rel="noopener">semantic similarity</a> between two vectors. This allows us to measures the degree of similarity between pieces of text based on their meaning, rather than just the words used like would be the case with the Bag-Of-Words model. This property of embeddings is depicted below in the classic example,</p>
<p align="center">
<figure>
<img src="https://github.com/mdh266/rag-jfk/blob/main/notebooks/images/embedding.png?raw=1" width="500" class="center">
<figcaption>
Source: https://medium.com/@hari4om/word-embedding-d816f643140
</figcaption>
</figure>
</p>
<p>Words that have similar &ldquo;meaning&rdquo; and or are used in the same context like &ldquo;cat&rdquo; and &ldquo;kitten&rdquo; are closer together when represented as vectors in the embedding space then they are to the word &ldquo;house&rdquo;. Embeddings allows to allow capture intrinsic relationships between words, such as the fact that &ldquo;man&rdquo; is to &ldquo;king&rdquo; as &ldquo;woman&rdquo; is to &ldquo;queen&rdquo;.</p>
<p>The ability to capture and measure the closeness of words and text using embeddings allows us to perform semantic search. Semantic search will be extremely important for RAG models and will be discussed more in the next post. For now I&rsquo;ll give the index a name and declare the dimension of the vectors it will hold.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span>index_name <span style="color:#f92672">=</span> <span style="color:#e6db74">&#34;prez-speeches&#34;</span>
</span></span><span style="display:flex;"><span>dim <span style="color:#f92672">=</span> <span style="color:#ae81ff">2048</span>
</span></span></code></pre></div><p>First I delete the index if it exists to clear it of all prior records.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#75715e"># delete the index if it exists</span>
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">if</span> pc<span style="color:#f92672">.</span>has_index(index_name):
</span></span><span style="display:flex;"><span>    pc<span style="color:#f92672">.</span>delete_index(index_name)
</span></span></code></pre></div><p>Now I&rsquo;ll create the index that contains vectors of size <code>dim</code>:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># create the index</span>
</span></span><span style="display:flex;"><span>pc<span style="color:#f92672">.</span>create_index(
</span></span><span style="display:flex;"><span>        name<span style="color:#f92672">=</span>index_name,
</span></span><span style="display:flex;"><span>        dimension<span style="color:#f92672">=</span>dim,
</span></span><span style="display:flex;"><span>        metric<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;cosine&#34;</span>,
</span></span><span style="display:flex;"><span>        spec<span style="color:#f92672">=</span>ServerlessSpec(
</span></span><span style="display:flex;"><span>                  cloud<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;aws&#34;</span>,
</span></span><span style="display:flex;"><span>                  region<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;us-east-1&#34;</span>
</span></span><span style="display:flex;"><span>        )
</span></span><span style="display:flex;"><span>)
</span></span></code></pre></div><pre><code>{
    &quot;name&quot;: &quot;prez-speeches&quot;,
    &quot;metric&quot;: &quot;cosine&quot;,
    &quot;host&quot;: &quot;prez-speeches-2307pwa.svc.aped-4627-b74a.pinecone.io&quot;,
    &quot;spec&quot;: {
        &quot;serverless&quot;: {
            &quot;cloud&quot;: &quot;aws&quot;,
            &quot;region&quot;: &quot;us-east-1&quot;
        }
    },
    &quot;status&quot;: {
        &quot;ready&quot;: true,
        &quot;state&quot;: &quot;Ready&quot;
    },
    &quot;vector_type&quot;: &quot;dense&quot;,
    &quot;dimension&quot;: 2048,
    &quot;deletion_protection&quot;: &quot;disabled&quot;,
    &quot;tags&quot;: null
}
</code></pre>
<p>Notice we have to declare a metric that is useful for the search. We can then get the statistics on the index we created,</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span>print(pc<span style="color:#f92672">.</span>Index(index_name)<span style="color:#f92672">.</span>describe_index_stats())
</span></span></code></pre></div><pre><code>/Users/mikeharmon/miniconda3/envs/llm_env/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html
  from .autonotebook import tqdm as notebook_tqdm


{'dimension': 2048,
 'index_fullness': 0.0,
 'metric': 'cosine',
 'namespaces': {},
 'total_vector_count': 0,
 'vector_type': 'dense'}
</code></pre>
<p>It shows us that we can hold vectors of size 2,048 dimensions and that we have a total of 0 vectors currently in the index.</p>
<p>To ingest documents into the database as vectors we instantiate the <a href="https://python.langchain.com/api_reference/pinecone/vectorstores/langchain_pinecone.vectorstores.PineconeVectorStore.html"  class="external-link" target="_blank" rel="noopener">PineconeVectorStore</a> object, connect it to the index and pass the embedding object,</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span>vectordb <span style="color:#f92672">=</span> PineconeVectorStore(
</span></span><span style="display:flex;"><span>                    pinecone_api_key<span style="color:#f92672">=</span>os<span style="color:#f92672">.</span>getenv(<span style="color:#e6db74">&#34;PINECONE_API_KEY&#34;</span>),
</span></span><span style="display:flex;"><span>                    embedding<span style="color:#f92672">=</span>embedding,
</span></span><span style="display:flex;"><span>                    index_name<span style="color:#f92672">=</span>index_name
</span></span><span style="display:flex;"><span>)
</span></span></code></pre></div><p>Now I&rsquo;ll load the documents into the index:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span>vectordb <span style="color:#f92672">=</span> vectordb<span style="color:#f92672">.</span>from_documents(
</span></span><span style="display:flex;"><span>                            documents<span style="color:#f92672">=</span>documents, 
</span></span><span style="display:flex;"><span>                            embedding<span style="color:#f92672">=</span>embedding, 
</span></span><span style="display:flex;"><span>                            index_name<span style="color:#f92672">=</span>index_name
</span></span><span style="display:flex;"><span>)
</span></span></code></pre></div><p>Under the hood LangChain will call the <a href="https://python.langchain.com/docs/integrations/text_embedding/openai/#embed-multiple-texts"  class="external-link" target="_blank" rel="noopener">embedding.embed_documents</a> method to convert the documents from text to numerical vectors and then ingest them into the database.</p>
<p>One of the beautiful things about LangChain is how the consistency of the API allows for easily swapping out and replacing different components of LLM applications. For instance one can switch to using a <a href="https://python.langchain.com/api_reference/chroma/vectorstores/langchain_chroma.vectorstores.Chroma.html#langchain_chroma.vectorstores.Chroma"  class="external-link" target="_blank" rel="noopener">Chroma</a> database and the syntax remains exactly the same! This characterstic of LangChain is important as each of the underlying databases and embedding models has their own API methods that are not necssarily consistent. Howevever, using LangChain we do have a consistent API and do not need to learn the different syntax for the different backends.</p>
<p>Now let&rsquo;s get the stats on the index again,</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span>print(pc<span style="color:#f92672">.</span>Index(index_name)<span style="color:#f92672">.</span>describe_index_stats())
</span></span></code></pre></div><pre><code>{'dimension': 2048,
 'index_fullness': 0.0,
 'metric': 'cosine',
 'namespaces': {'': {'vector_count': 180}},
 'total_vector_count': 180,
 'vector_type': 'dense'}
</code></pre>
<p>We can see that there are vectors ingested!</p>
<p>Now I can get the Pinecone API directl to get the index to use it to perform semantic search,</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span>index <span style="color:#f92672">=</span> pc<span style="color:#f92672">.</span>Index(index_name)
</span></span></code></pre></div><p>This allows us to perform search for the semanticly closest documents to the queries. For instance I&rsquo;ll use the query,</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span>question <span style="color:#f92672">=</span> <span style="color:#e6db74">&#34;How did Kennedy feel about the Berlin Wall?&#34;</span>
</span></span></code></pre></div><p>Before I can perform search on the vector database I need to embed this text into a numerical vector,</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span>query <span style="color:#f92672">=</span> embedding<span style="color:#f92672">.</span>embed_query(question)
</span></span></code></pre></div><p>Now I can find the 5 closest vectors to the query in the database,</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span>matches <span style="color:#f92672">=</span> index<span style="color:#f92672">.</span>query(vector<span style="color:#f92672">=</span>query, top_k<span style="color:#f92672">=</span><span style="color:#ae81ff">5</span>)
</span></span><span style="display:flex;"><span>matches
</span></span></code></pre></div><pre><code>{'matches': [{'id': 'b9e573a6-d9f9-4306-a6e3-72ac769643dd',
              'score': 0.436862975,
              'values': []},
             {'id': 'd0245e9a-b4f2-46e6-a6d0-07ee3afbad16',
              'score': 0.422326,
              'values': []},
             {'id': 'a6bcd4fa-90a3-46b2-a48d-105115ccaed7',
              'score': 0.394667208,
              'values': []},
             {'id': 'ffe2db4a-6983-4cde-a853-658080619575',
              'score': 0.35799697,
              'values': []},
             {'id': 'b7c5ebca-1886-4670-9acd-55ce4e402c2c',
              'score': 0.352600902,
              'values': []}],
 'namespace': '',
 'usage': {'read_units': 5}}
</code></pre>
<p>The results contain the similarity score as well as the document <code>id</code>. I can get the most relevant document by getting the first <code>id</code> in the results:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span>id <span style="color:#f92672">=</span> matches[<span style="color:#e6db74">&#34;matches&#34;</span>][<span style="color:#ae81ff">0</span>]<span style="color:#f92672">.</span>get(<span style="color:#e6db74">&#39;id&#39;</span>)
</span></span></code></pre></div><p>Then I can get the document for that <code>id</code> with the <code>fetch</code> method of the index:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span>result <span style="color:#f92672">=</span> index<span style="color:#f92672">.</span>fetch([id])
</span></span><span style="display:flex;"><span>result<span style="color:#f92672">.</span>vectors[id][<span style="color:#e6db74">&#34;metadata&#34;</span>]
</span></span></code></pre></div><pre><code>{'filename': 'berlin-w-germany-rudolph-wilde-platz-19630626',
 'seq_num': 1.0,
 'source': 'gs://prezkennedyspeches/berlin-w-germany-rudolph-wilde-platz-19630626.json',
 'text': 'Freedom has many difficulties and democracy is not perfect, but we have never had to put a wall up to keep our people in, to prevent them from leaving us. I want to say, on behalf of my countrymen, who live many miles away on the other side of the Atlantic, who are far distant from you, that they take the greatest pride that they have been able to share with you, even from a distance, the story of the last 18 years. I know of no town, no city, that has been besieged for 18 years that still lives with the vitality and the force, and the hope and the determination of the city of West Berlin. While the wall is the most obvious and vivid demonstration of the failures of the Communist system, for all the world to see, we take no satisfaction in it, for it is, as your Mayor has said, an offense not only against history but an offense against humanity, separating families, dividing husbands and wives and brothers and sisters, and dividing a people who wish to be joined together.\nWhat is true of this city is true of Germany--real, lasting peace in Europe can never be assured as long as one German out of four is denied the elementary right of free men, and that is to make a free choice. In 18 years of peace and good faith, this generation of Germans has earned the right to be free, including the right to unite their families and their nation in lasting peace, with good will to all people. You live in a defended island of freedom, but your life is part of the main. So let me ask you as I close, to lift your eyes beyond the dangers of today, to the hopes of tomorrow, beyond the freedom merely of this city of Berlin, or your country of Germany, to the advance of freedom everywhere, beyond the wall to the day of peace with justice, beyond yourselves and ourselves to all mankind.',
 'title': 'Remarks of President John F. Kennedy at the Rudolph Wilde Platz, Berlin, June 26, 1963',
 'url': 'https://www.jfklibrary.org//archives/other-resources/john-f-kennedy-speeches/berlin-w-germany-rudolph-wilde-platz-19630626'}
</code></pre>
<p>I can repeat the same exercise using the LangChain <a href="https://python.langchain.com/api_reference/pinecone/vectorstores/langchain_pinecone.vectorstores.PineconeVectorStore.html"  class="external-link" target="_blank" rel="noopener">PineconeVectorStore</a> api:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span>results <span style="color:#f92672">=</span> vectordb<span style="color:#f92672">.</span>search(query<span style="color:#f92672">=</span>question, search_type<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;similarity&#34;</span>)
</span></span></code></pre></div><div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span>results[<span style="color:#ae81ff">0</span>]<span style="color:#f92672">.</span>metadata
</span></span></code></pre></div><pre><code>{'filename': 'berlin-w-germany-rudolph-wilde-platz-19630626',
 'seq_num': 1.0,
 'source': 'gs://prezkennedyspeches/berlin-w-germany-rudolph-wilde-platz-19630626.json',
 'title': 'Remarks of President John F. Kennedy at the Rudolph Wilde Platz, Berlin, June 26, 1963',
 'url': 'https://www.jfklibrary.org//archives/other-resources/john-f-kennedy-speeches/berlin-w-germany-rudolph-wilde-platz-19630626'}
</code></pre>
<p>The results are the same which is to be expected!</p>
<h3 id="5-next-steps">
  5. Next Steps <a class="anchor" id="fifth-bullet"></a>
  <a class="heading-link" href="#5-next-steps">
    <i class="fa-solid fa-link" aria-hidden="true" title="Link to heading"></i>
    <span class="sr-only">Link to heading</span>
  </a>
</h3>
<hr>
<p>In this post I covered how to scape websites using the <a href="https://docs.python.org/3/library/asyncio.html"  class="external-link" target="_blank" rel="noopener">aysncio</a> and write them to <a href="https://cloud.google.com/storage?hl=en"  class="external-link" target="_blank" rel="noopener">Google Cloud Storage</a>. After that we covered how to use <a href="https://www.langchain.com/"  class="external-link" target="_blank" rel="noopener">LangChain</a> to load text from cloud storage, chunk and embedded it using <a href="https://build.nvidia.com/nvidia/llama-3_2-nv-embedqa-1b-v2"  class="external-link" target="_blank" rel="noopener">Nvidia Embeddings</a>. Then we coved how to store the embedded documents as vectors in a <a href="https://pinecone.io/"  class="external-link" target="_blank" rel="noopener">Pinecone vector database</a> and perform semantic search. In the next blog post I will build off using semantic search with Pinecone to build and deploy a RAG application that can answer questions on President Kennedy&rsquo;s speeches. I actually rewrote the notebook as a script that uses Langchain&rsquo;s async frameworks to load all 800+ JFK speeches into the Pinecone database and it is <a href="https://github.com/mdh266/rag-jfk/blob/main/scripts/load.py"  class="external-link" target="_blank" rel="noopener">here</a> if you are interested.</p>

      </div>


      <footer>
        

<section class="see-also">
  
    
    
    
      <h3 id="see-also-in-llms">
        See also in LLMs
        <a class="heading-link" href="#see-also-in-llms">
          <i class="fa-solid fa-link" aria-hidden="true" title="Link to heading"></i>
          <span class="sr-only">Link to heading</span>
        </a>
      </h3>
      <nav>
        <ul>
        
        
          
            <li>
              <a href="/posts/rag_jfk2/">Retrieval Augmented Generation On JFK Speeches: Part 2</a>
            </li>
          
        
          
        
          
            <li>
              <a href="/posts/chatbot2/">Building &amp; Deploying A Serverless Multimodal ChatBot: Part 2</a>
            </li>
          
        
          
            <li>
              <a href="/posts/chatbot1/">Building &amp; Deploying A Serverless Multimodal ChatBot: Part 1</a>
            </li>
          
        
        </ul>
      </nav>
    
  
</section>


        
        
        
        
        
        
        
      </footer>
    </article>

    
  </section>

    </div>

    <footer class="footer">
  <section class="container">
    ©
    
      2016 -
    
    2025
     Mike Harmon 
    ·
    
    Powered by <a href="https://gohugo.io/" target="_blank" rel="noopener">Hugo</a> & <a href="https://github.com/luizdepra/hugo-coder/" target="_blank" rel="noopener">Coder</a>.
    
  </section>
</footer>

  </main>

  

  
  
  <script src="/js/coder.js"></script>
  

  

  


  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  
</body>
</html>
