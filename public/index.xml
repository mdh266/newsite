<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Mike Harmon</title>
    <link>http://localhost:1313/</link>
    <description>Recent content on Mike Harmon</description>
    <generator>Hugo</generator>
    <language>en</language>
    <lastBuildDate>Fri, 01 Aug 2025 00:00:00 +0000</lastBuildDate>
    <atom:link href="http://localhost:1313/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Text Classification 5: Fine Tuning BERT With HuggingFace</title>
      <link>http://localhost:1313/posts/bert/</link>
      <pubDate>Fri, 01 Aug 2025 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/posts/bert/</guid>
      <description>&lt;h2 id=&#34;contents&#34;&gt;&#xA;  Contents&#xA;  &lt;a class=&#34;heading-link&#34; href=&#34;#contents&#34;&gt;&#xA;    &lt;i class=&#34;fa-solid fa-link&#34; aria-hidden=&#34;true&#34; title=&#34;Link to heading&#34;&gt;&lt;/i&gt;&#xA;    &lt;span class=&#34;sr-only&#34;&gt;Link to heading&lt;/span&gt;&#xA;  &lt;/a&gt;&#xA;&lt;/h2&gt;&#xA;&lt;hr&gt;&#xA;&lt;p&gt;&lt;strong&gt;&lt;a href=&#34;#first-bullet&#34; &gt;1. Introduction&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt;&#xA;&lt;p&gt;&lt;strong&gt;&lt;a href=&#34;#second-bullet&#34; &gt;2. Collecting Data&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt;&#xA;&lt;p&gt;&lt;strong&gt;&lt;a href=&#34;#third-bullet&#34; &gt;3. Hugging Face Datasets, Tokenizers &amp;amp; Models&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt;&#xA;&lt;p&gt;&lt;strong&gt;&lt;a href=&#34;#fourth-bullet&#34; &gt;4. Fine Tuning BERT and Hugging Face Model Hub&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt;&#xA;&lt;p&gt;&lt;strong&gt;&lt;a href=&#34;#fifth-bullet&#34; &gt;5. Using The Model With Hugging Face Pipelines&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt;&#xA;&lt;p&gt;&lt;strong&gt;&lt;a href=&#34;#sixth-bullet&#34; &gt;6. Next Steps&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt;&#xA;&lt;h2 id=&#34;1-introduction&#34;&gt;&#xA;  1. Introduction &lt;a class=&#34;anchor&#34; id=&#34;first-bullet&#34;&gt;&lt;/a&gt;&#xA;  &lt;a class=&#34;heading-link&#34; href=&#34;#1-introduction&#34;&gt;&#xA;    &lt;i class=&#34;fa-solid fa-link&#34; aria-hidden=&#34;true&#34; title=&#34;Link to heading&#34;&gt;&lt;/i&gt;&#xA;    &lt;span class=&#34;sr-only&#34;&gt;Link to heading&lt;/span&gt;&#xA;  &lt;/a&gt;&#xA;&lt;/h2&gt;&#xA;&lt;hr&gt;&#xA;&lt;p&gt;In this notebook, I will walk through the complete process of fine-tuning a &lt;a href=&#34;https://en.wikipedia.org/wiki/BERT_%28language_model%29&#34;  class=&#34;external-link&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;BERT (Bidirectional Encoder Representations from Transformers)&lt;/a&gt; model using the &lt;a href=&#34;https://huggingface.co/&#34;  class=&#34;external-link&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;HuggingFace ecosystem&lt;/a&gt;. BERT has become a cornerstone of modern NLP due to its ability to capture bidirectional context and deliver strong performance across a wide range of language understanding tasks such as classification, named entity resolution and question answering. In this post I will build off of &lt;a href=&#34;https://michael-harmon.com/blog/NLP4.html&#34;  class=&#34;external-link&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;prior posts on text classification&lt;/a&gt; by fine tuning a BERT model to classify the topic of papers in &lt;a href=&#34;arxiv.org&#34; &gt;arxiv&lt;/a&gt; by their abstract text. By the end of this post, I will have a working, fine-tuned BERT model ready for inference on the &lt;a href=&#34;https://huggingface.co/models&#34;  class=&#34;external-link&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Hugging Face Model Hub&lt;/a&gt;.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Retrieval Augmented Generation On JFK Speeches: Part 2</title>
      <link>http://localhost:1313/posts/rag_jfk2/</link>
      <pubDate>Thu, 03 Apr 2025 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/posts/rag_jfk2/</guid>
      <description>&lt;h3 id=&#34;contents&#34;&gt;&#xA;  Contents&#xA;  &lt;a class=&#34;heading-link&#34; href=&#34;#contents&#34;&gt;&#xA;    &lt;i class=&#34;fa-solid fa-link&#34; aria-hidden=&#34;true&#34; title=&#34;Link to heading&#34;&gt;&lt;/i&gt;&#xA;    &lt;span class=&#34;sr-only&#34;&gt;Link to heading&lt;/span&gt;&#xA;  &lt;/a&gt;&#xA;&lt;/h3&gt;&#xA;&lt;hr&gt;&#xA;&lt;p&gt;&lt;strong&gt;&lt;a href=&#34;#first-bullet&#34; &gt;1. Introduction to RAG &lt;/a&gt;&lt;/strong&gt;&lt;/p&gt;&#xA;&lt;p&gt;&lt;strong&gt;&lt;a href=&#34;#second-bullet&#34; &gt;2. Retriving Documents With Vector (Semantic) Search&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt;&#xA;&lt;p&gt;&lt;strong&gt;&lt;a href=&#34;#third-bullet&#34; &gt;3. Building A RAG Pipeline&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt;&#xA;&lt;!-- __[4. A CI/CD Pipeline For RAG](#fourth-bullet)__ --&gt;&#xA;&lt;p&gt;&lt;strong&gt;&lt;a href=&#34;#fourth-bullet&#34; &gt;4. Deploying A RAG Application&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt;&#xA;&lt;p&gt;&lt;strong&gt;&lt;a href=&#34;fifth-bullet&#34; &gt;5. Conclusions&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt;&#xA;&lt;h3 id=&#34;1-introduction-to-rag&#34;&gt;&#xA;  1. Introduction to RAG &lt;a class=&#34;anchor&#34; id=&#34;first-bullet&#34;&gt;&lt;/a&gt;&#xA;  &lt;a class=&#34;heading-link&#34; href=&#34;#1-introduction-to-rag&#34;&gt;&#xA;    &lt;i class=&#34;fa-solid fa-link&#34; aria-hidden=&#34;true&#34; title=&#34;Link to heading&#34;&gt;&lt;/i&gt;&#xA;    &lt;span class=&#34;sr-only&#34;&gt;Link to heading&lt;/span&gt;&#xA;  &lt;/a&gt;&#xA;&lt;/h3&gt;&#xA;&lt;hr&gt;&#xA;&lt;p&gt;In my &lt;a href=&#34;http://michael-harmon.com/blog/ragjfk1.html&#34;  class=&#34;external-link&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;last post&lt;/a&gt; on RAG I discussed how to ingest President Kennedy&amp;rsquo;s speeches into a &lt;a href=&#34;https://www.pinecone.io/&#34;  class=&#34;external-link&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Pinecone&lt;/a&gt; vector database and perform semantic search  using both Pinecone&amp;rsquo;s API as well as using the &lt;a href=&#34;https://www.langchain.com/&#34;  class=&#34;external-link&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Langchain&lt;/a&gt; API. I used Pinecone for a vector database since its cloud based, fully managed and of course has a free tier. In this post I will expand upon my prior work and build out a &lt;a href=&#34;https://en.wikipedia.org/wiki/Retrieval-augmented_generation&#34;  class=&#34;external-link&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Retrivial Augmented Generation (RAG)&lt;/a&gt; pipeline using Langchain. I will deploy this as a &lt;a href=&#34;https://streamlit.io/&#34;  class=&#34;external-link&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Streamlit&lt;/a&gt; application to be able to answer questions on President Kennedy.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Retrieval Augmented Generation On JFK Speeches: Part 1</title>
      <link>http://localhost:1313/posts/rag_jfk1/</link>
      <pubDate>Thu, 13 Mar 2025 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/posts/rag_jfk1/</guid>
      <description>&lt;h3 id=&#34;contents&#34;&gt;&#xA;  Contents&#xA;  &lt;a class=&#34;heading-link&#34; href=&#34;#contents&#34;&gt;&#xA;    &lt;i class=&#34;fa-solid fa-link&#34; aria-hidden=&#34;true&#34; title=&#34;Link to heading&#34;&gt;&lt;/i&gt;&#xA;    &lt;span class=&#34;sr-only&#34;&gt;Link to heading&lt;/span&gt;&#xA;  &lt;/a&gt;&#xA;&lt;/h3&gt;&#xA;&lt;p&gt;&lt;strong&gt;&lt;a href=&#34;#first-bullet&#34; &gt;1. Introduction&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt;&#xA;&lt;p&gt;&lt;strong&gt;&lt;a href=&#34;#second-bullet&#34; &gt;2. Scraping JFK Speeches using Asyncio&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt;&#xA;&lt;p&gt;&lt;strong&gt;&lt;a href=&#34;#third-bullet&#34; &gt;3. Loading and Embedding Speeches&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt;&#xA;&lt;p&gt;&lt;strong&gt;&lt;a href=&#34;#fourth-bullet&#34; &gt;4. Ingesting Speeches Into A Pinecone Vector Database &lt;/a&gt;&lt;/strong&gt;&lt;/p&gt;&#xA;&lt;p&gt;&lt;strong&gt;&lt;a href=&#34;#fifth-bullet&#34; &gt;5. Next Steps&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt;&#xA;&lt;h3 id=&#34;1-introduction&#34;&gt;&#xA;  1. Introduction &lt;a class=&#34;anchor&#34; id=&#34;first-bullet&#34;&gt;&lt;/a&gt;&#xA;  &lt;a class=&#34;heading-link&#34; href=&#34;#1-introduction&#34;&gt;&#xA;    &lt;i class=&#34;fa-solid fa-link&#34; aria-hidden=&#34;true&#34; title=&#34;Link to heading&#34;&gt;&lt;/i&gt;&#xA;    &lt;span class=&#34;sr-only&#34;&gt;Link to heading&lt;/span&gt;&#xA;  &lt;/a&gt;&#xA;&lt;/h3&gt;&#xA;&lt;hr&gt;&#xA;&lt;p&gt;In this post I venture into building a Retrieval Augumented Generation (RAG) application that has been &amp;ldquo;trained&amp;rdquo; on President John F. Kennedy speeches. In past posts I covered how I &lt;a href=&#34;http://michael-harmon.com/blog/jfk1.html&#34;  class=&#34;external-link&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;collected JFK speeches&lt;/a&gt; and &lt;a href=&#34;http://michael-harmon.com/blog/jfk2.html&#34;  class=&#34;external-link&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;built a &amp;ldquo;speech writer&amp;rdquo;&lt;/a&gt; using a &lt;a href=&#34;https://en.wikipedia.org/wiki/Gated_recurrent_unit&#34;  class=&#34;external-link&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Gated Recurrent Unit (GRU) Neural Network&lt;/a&gt;. In this post I improve upon on the prior work to build a RAG pipeline.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Building &amp; Deploying A Serverless Multimodal ChatBot: Part 2</title>
      <link>http://localhost:1313/posts/chatbot2/</link>
      <pubDate>Thu, 09 Jan 2025 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/posts/chatbot2/</guid>
      <description>&lt;h3 id=&#34;contents&#34;&gt;&#xA;  Contents&#xA;  &lt;a class=&#34;heading-link&#34; href=&#34;#contents&#34;&gt;&#xA;    &lt;i class=&#34;fa-solid fa-link&#34; aria-hidden=&#34;true&#34; title=&#34;Link to heading&#34;&gt;&lt;/i&gt;&#xA;    &lt;span class=&#34;sr-only&#34;&gt;Link to heading&lt;/span&gt;&#xA;  &lt;/a&gt;&#xA;&lt;/h3&gt;&#xA;&lt;hr&gt;&#xA;&lt;p&gt;&lt;strong&gt;&lt;a href=&#34;#first-bullet&#34; &gt;1. Introduction&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt;&#xA;&lt;p&gt;&lt;strong&gt;&lt;a href=&#34;#second-bullet&#34; &gt;2. Docker &amp;amp; Docker Hub&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt;&#xA;&lt;p&gt;&lt;strong&gt;&lt;a href=&#34;#third-bullet&#34; &gt;3. GitHub Actions For CI/CD&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt;&#xA;&lt;p&gt;&lt;strong&gt;&lt;a href=&#34;#fourth-bullet&#34; &gt;4. Deploying On Google Cloud Run&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt;&#xA;&lt;p&gt;&lt;strong&gt;&lt;a href=&#34;#fifth-bullet&#34; &gt;5. Conclusions&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt;&#xA;&lt;h3 id=&#34;introduction&#34;&gt;&#xA;  Introduction &lt;a class=&#34;anchor&#34; id=&#34;first-bullet&#34;&gt;&lt;/a&gt;&#xA;  &lt;a class=&#34;heading-link&#34; href=&#34;#introduction&#34;&gt;&#xA;    &lt;i class=&#34;fa-solid fa-link&#34; aria-hidden=&#34;true&#34; title=&#34;Link to heading&#34;&gt;&lt;/i&gt;&#xA;    &lt;span class=&#34;sr-only&#34;&gt;Link to heading&lt;/span&gt;&#xA;  &lt;/a&gt;&#xA;&lt;/h3&gt;&#xA;&lt;hr&gt;&#xA;&lt;p&gt;In my &lt;a href=&#34;http://michael-harmon.com/blog/chatbot1.html&#34;  class=&#34;external-link&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;last post&lt;/a&gt; I went over how to create a create speech based chatbot app with a &lt;a href=&#34;https://en.wikipedia.org/wiki/Large_language_model&#34;  class=&#34;external-link&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Large Language Model (LLM)&lt;/a&gt; using &lt;a href=&#34;https://www.langchain.com/&#34;  class=&#34;external-link&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;LangChain&lt;/a&gt;, &lt;a href=&#34;https://ai.meta.com/blog/meta-llama-3/&#34;  class=&#34;external-link&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Llama 3&lt;/a&gt;, &lt;a href=&#34;&#34; &gt;Google Cloud API&lt;/a&gt; and &lt;a href=&#34;https://streamlit.io/&#34;  class=&#34;external-link&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Streamlit&lt;/a&gt;.&lt;/p&gt;&#xA;&lt;p&gt;In this post I&amp;rsquo;ll cover how to deploy this app using &lt;a href=&#34;https://www.docker.com/&#34;  class=&#34;external-link&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Docker&lt;/a&gt; for containerization. Containerizing the app will allow us to run it both locally and on the cloud. Then I&amp;rsquo;ll cover &lt;a href=&#34;https://github.com/features/actions&#34;  class=&#34;external-link&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;GitHub Actions&lt;/a&gt; for automatically building the image and pushing it to &lt;a href=&#34;https://hub.docker.com/&#34;  class=&#34;external-link&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Docker Hub&lt;/a&gt; where it can be pulled and run on &lt;a href=&#34;https://cloud.google.com/run&#34;  class=&#34;external-link&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Google Cloud Run&lt;/a&gt; to create a serverless application.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Building &amp; Deploying A Serverless Multimodal ChatBot: Part 1</title>
      <link>http://localhost:1313/posts/chatbot1/</link>
      <pubDate>Mon, 23 Dec 2024 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/posts/chatbot1/</guid>
      <description>&lt;h2 id=&#34;contents&#34;&gt;&#xA;  Contents&#xA;  &lt;a class=&#34;heading-link&#34; href=&#34;#contents&#34;&gt;&#xA;    &lt;i class=&#34;fa-solid fa-link&#34; aria-hidden=&#34;true&#34; title=&#34;Link to heading&#34;&gt;&lt;/i&gt;&#xA;    &lt;span class=&#34;sr-only&#34;&gt;Link to heading&lt;/span&gt;&#xA;  &lt;/a&gt;&#xA;&lt;/h2&gt;&#xA;&lt;hr&gt;&#xA;&lt;p&gt;&lt;strong&gt;&lt;a href=&#34;#first-bullet&#34; &gt;1. Introduction&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt;&#xA;&lt;p&gt;&lt;strong&gt;&lt;a href=&#34;#second-bullet&#34; &gt;2. Chatting With Llama 3 Using LangChain &amp;amp; Groq&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt;&#xA;&lt;p&gt;&lt;strong&gt;&lt;a href=&#34;#third-bullet&#34; &gt;3. Speech &amp;amp; Text With Google Cloud API&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt;&#xA;&lt;p&gt;&lt;strong&gt;&lt;a href=&#34;#fourth-bullet&#34; &gt;4. Putting It Together As An App Using Streamlit&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt;&#xA;&lt;p&gt;&lt;strong&gt;&lt;a href=&#34;#fifth-bullet&#34; &gt;5. Next Steps&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt;&#xA;&lt;h2 id=&#34;1-introduction&#34;&gt;&#xA;  1. Introduction &lt;a class=&#34;anchor&#34; id=&#34;first-bullet&#34;&gt;&lt;/a&gt;&#xA;  &lt;a class=&#34;heading-link&#34; href=&#34;#1-introduction&#34;&gt;&#xA;    &lt;i class=&#34;fa-solid fa-link&#34; aria-hidden=&#34;true&#34; title=&#34;Link to heading&#34;&gt;&lt;/i&gt;&#xA;    &lt;span class=&#34;sr-only&#34;&gt;Link to heading&lt;/span&gt;&#xA;  &lt;/a&gt;&#xA;&lt;/h2&gt;&#xA;&lt;hr&gt;&#xA;&lt;p&gt;In this blog post I will go over how to create a create multimodal chatbot using a &lt;a href=&#34;https://en.wikipedia.org/wiki/Large_language_model&#34;  class=&#34;external-link&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Large Language Model (LLM)&lt;/a&gt;. Specifically, I&amp;rsquo;ll build an app that you can speak to and get an audio reply. The app will also optionally transcribe conversation. I will go over how to do this all in a serverless framework and using cloud-based APIs so that (baring the app getting really popular) the costs will be next to nothing!&lt;/p&gt;</description>
    </item>
    <item>
      <title>Polars &amp; DuckDB: DataFrames and SQL For Python Without Pandas</title>
      <link>http://localhost:1313/posts/polarsduckdb/</link>
      <pubDate>Wed, 19 Jul 2023 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/posts/polarsduckdb/</guid>
      <description>&lt;h2 id=&#34;contents&#34;&gt;&#xA;  Contents&#xA;  &lt;a class=&#34;heading-link&#34; href=&#34;#contents&#34;&gt;&#xA;    &lt;i class=&#34;fa-solid fa-link&#34; aria-hidden=&#34;true&#34; title=&#34;Link to heading&#34;&gt;&lt;/i&gt;&#xA;    &lt;span class=&#34;sr-only&#34;&gt;Link to heading&lt;/span&gt;&#xA;  &lt;/a&gt;&#xA;&lt;/h2&gt;&#xA;&lt;hr&gt;&#xA;&lt;p&gt;&lt;strong&gt;&lt;a href=&#34;#first-bullet&#34; &gt;1. Introduction&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt;&#xA;&lt;p&gt;&lt;strong&gt;&lt;a href=&#34;#second-bullet&#34; &gt;2. Getting Set Up On AWS with Docker&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt;&#xA;&lt;p&gt;&lt;strong&gt;&lt;a href=&#34;#third-bullet&#34; &gt;3. Intro To Polars&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt;&#xA;&lt;p&gt;&lt;strong&gt;&lt;a href=&#34;#fourth-bullet&#34; &gt;4. DuckDB To The Rescue For SQL&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt;&#xA;&lt;p&gt;&lt;strong&gt;&lt;a href=&#34;#fifth&#34; &gt;5. Conclusions&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt;&#xA;&lt;h2 id=&#34;introduction&#34;&gt;&#xA;  Introduction &lt;a class=&#34;anchor&#34; id=&#34;first-bullet&#34;&gt;&lt;/a&gt;&#xA;  &lt;a class=&#34;heading-link&#34; href=&#34;#introduction&#34;&gt;&#xA;    &lt;i class=&#34;fa-solid fa-link&#34; aria-hidden=&#34;true&#34; title=&#34;Link to heading&#34;&gt;&lt;/i&gt;&#xA;    &lt;span class=&#34;sr-only&#34;&gt;Link to heading&lt;/span&gt;&#xA;  &lt;/a&gt;&#xA;&lt;/h2&gt;&#xA;&lt;hr&gt;&#xA;&lt;p&gt;In the last few years there has been an explosion of dataframe alternatives to &lt;a href=&#34;https://pandas.pydata.org/&#34;  class=&#34;external-link&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Pandas&lt;/a&gt; due to its &lt;a href=&#34;https://insightsndata.com/what-are-the-limitations-of-pandas-35d462990c43&#34;  class=&#34;external-link&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;limitations&lt;/a&gt;. Even the original author, Wes McKinney, wrote a blog post about &lt;a href=&#34;https://wesmckinney.com/blog/apache-arrow-pandas-internals/&#34;  class=&#34;external-link&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;10 Things I Hate About Pandas&lt;/a&gt;.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Creating An AI-Based JFK Speech Writer: Part 2</title>
      <link>http://localhost:1313/posts/jfk2/</link>
      <pubDate>Sat, 01 Apr 2023 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/posts/jfk2/</guid>
      <description>&lt;h2 id=&#34;contents&#34;&gt;&#xA;  Contents&#xA;  &lt;a class=&#34;heading-link&#34; href=&#34;#contents&#34;&gt;&#xA;    &lt;i class=&#34;fa-solid fa-link&#34; aria-hidden=&#34;true&#34; title=&#34;Link to heading&#34;&gt;&lt;/i&gt;&#xA;    &lt;span class=&#34;sr-only&#34;&gt;Link to heading&lt;/span&gt;&#xA;  &lt;/a&gt;&#xA;&lt;/h2&gt;&#xA;&lt;hr&gt;&#xA;&lt;p&gt;&lt;strong&gt;&lt;a href=&#34;#first-bullet&#34; &gt;1. Introduction&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt;&#xA;&lt;p&gt;&lt;strong&gt;&lt;a href=&#34;#second-bullet&#34; &gt;2. Data Preparation&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt;&#xA;&lt;p&gt;&lt;strong&gt;&lt;a href=&#34;#third-bullet&#34; &gt;3. A Bidirectional GRU Model&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt;&#xA;&lt;p&gt;&lt;strong&gt;&lt;a href=&#34;#fourth-bullet&#34; &gt;4. Generating Text&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt;&#xA;&lt;p&gt;&lt;strong&gt;&lt;a href=&#34;#fifth-bullet&#34; &gt;5. Next Steps&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt;&#xA;&lt;h2 id=&#34;introduction&#34;&gt;&#xA;  Introduction &lt;a class=&#34;anchor&#34; id=&#34;first-bullet&#34;&gt;&lt;/a&gt;&#xA;  &lt;a class=&#34;heading-link&#34; href=&#34;#introduction&#34;&gt;&#xA;    &lt;i class=&#34;fa-solid fa-link&#34; aria-hidden=&#34;true&#34; title=&#34;Link to heading&#34;&gt;&lt;/i&gt;&#xA;    &lt;span class=&#34;sr-only&#34;&gt;Link to heading&lt;/span&gt;&#xA;  &lt;/a&gt;&#xA;&lt;/h2&gt;&#xA;&lt;hr&gt;&#xA;&lt;p&gt;In this blog post I follow up on the last &lt;a href=&#34;http://michael-harmon.com/blog/jfk1.html&#34;  class=&#34;external-link&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;post&lt;/a&gt; and develop a model for text generation using &lt;a href=&#34;https://en.wikipedia.org/wiki/Recurrent_neural_network&#34;  class=&#34;external-link&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Recurrent Neural Networks&lt;/a&gt;. I&amp;rsquo;ll build a bi-directional &lt;a href=&#34;https://en.wikipedia.org/wiki/Gated_recurrent_unit&#34;  class=&#34;external-link&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;gated recurrent unit (GRU)&lt;/a&gt; that is trained on speeches made by &lt;a href=&#34;https://en.wikipedia.org/wiki/John_F._Kennedy&#34;  class=&#34;external-link&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;President John F. Kennedy&lt;/a&gt;. Specifically, I&amp;rsquo;ll go over how to build a model that predicts the &amp;ldquo;next word&amp;rdquo; in a sentence based off a sequence of the words coming before it. This project was more challenging than I initially anticipated due to the data preparation needs of the problem as well as the fact the performance is hard to quantify. The data preparation was more involved then other posts that I have done on natural language processing since it involves modeling a sequences of words instead of using a &amp;ldquo;&lt;a href=&#34;https://en.wikipedia.org/wiki/Bag-of-words_model&#34;  class=&#34;external-link&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;bag-of-words&lt;/a&gt;.&amp;rdquo; I&amp;rsquo;ll go over some of these details more in the post.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Creating An AI-Based JFK Speech Writer: Part 1</title>
      <link>http://localhost:1313/posts/jfk1/</link>
      <pubDate>Fri, 23 Dec 2022 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/posts/jfk1/</guid>
      <description>&lt;h2 id=&#34;introduction&#34;&gt;&#xA;  Introduction&#xA;  &lt;a class=&#34;heading-link&#34; href=&#34;#introduction&#34;&gt;&#xA;    &lt;i class=&#34;fa-solid fa-link&#34; aria-hidden=&#34;true&#34; title=&#34;Link to heading&#34;&gt;&lt;/i&gt;&#xA;    &lt;span class=&#34;sr-only&#34;&gt;Link to heading&lt;/span&gt;&#xA;  &lt;/a&gt;&#xA;&lt;/h2&gt;&#xA;&lt;hr&gt;&#xA;&lt;p&gt;One of the most quintessential projects to complete when getting started with Deep Learning and Natural Language Processing is with text generation with Recurrent Neural Networks. The internet is littered with examples of people training on books of Shakespeare and using the network to generate new text that mimics Shakespeare&amp;rsquo;s style. I wanted to do something along these lines, but a little more creative. Many would agree one of the best orators of all time would have to be John F. Kennedy. I am a personally a big nerd of an President Kennedy&amp;rsquo;s speeches and spent many hours listening to his words. So I started this project to see if could write a neural network to generate a Kennedy-like speech writer.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Text Classification 4: Deep Learning With Tensorflow &amp; Optuna</title>
      <link>http://localhost:1313/posts/nlp4/</link>
      <pubDate>Tue, 22 Nov 2022 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/posts/nlp4/</guid>
      <description>&lt;h2 id=&#34;contents&#34;&gt;&#xA;  Contents&#xA;  &lt;a class=&#34;heading-link&#34; href=&#34;#contents&#34;&gt;&#xA;    &lt;i class=&#34;fa-solid fa-link&#34; aria-hidden=&#34;true&#34; title=&#34;Link to heading&#34;&gt;&lt;/i&gt;&#xA;    &lt;span class=&#34;sr-only&#34;&gt;Link to heading&lt;/span&gt;&#xA;  &lt;/a&gt;&#xA;&lt;/h2&gt;&#xA;&lt;hr&gt;&#xA;&lt;p&gt;&lt;strong&gt;&lt;a href=&#34;#first-bullet&#34; &gt;1. Introduction&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt;&#xA;&lt;p&gt;&lt;strong&gt;&lt;a href=&#34;#second-bullet&#34; &gt;2. Vectorizing Text&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt;&#xA;&lt;p&gt;&lt;strong&gt;&lt;a href=&#34;#third-bullet&#34; &gt;3. Handling Imbalance In The Data&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt;&#xA;&lt;p&gt;&lt;strong&gt;&lt;a href=&#34;#fourth-bullet&#34; &gt;4. Building A Convolutional Neural Network With Keras&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt;&#xA;&lt;p&gt;&lt;strong&gt;&lt;a href=&#34;#fifth-bullet&#34; &gt;5. Hyperparameter Tuning with Optuna&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt;&#xA;&lt;p&gt;&lt;strong&gt;&lt;a href=&#34;#sixth-bullet&#34; &gt;6. Next Steps&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt;&#xA;&lt;h2 id=&#34;introduction&#34;&gt;&#xA;  Introduction &lt;a class=&#34;anchor&#34; id=&#34;first-bullet&#34;&gt;&lt;/a&gt;&#xA;  &lt;a class=&#34;heading-link&#34; href=&#34;#introduction&#34;&gt;&#xA;    &lt;i class=&#34;fa-solid fa-link&#34; aria-hidden=&#34;true&#34; title=&#34;Link to heading&#34;&gt;&lt;/i&gt;&#xA;    &lt;span class=&#34;sr-only&#34;&gt;Link to heading&lt;/span&gt;&#xA;  &lt;/a&gt;&#xA;&lt;/h2&gt;&#xA;&lt;hr&gt;&#xA;&lt;p&gt;In this post I want to extend on the last &lt;a href=&#34;http://michael-harmon.com/blog/NLP2.html&#34;  class=&#34;external-link&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;model&lt;/a&gt; in my blog series on text classification where I used a SVM to predict the topic of papers in arxiv based on their abstract. For reference the topics were &amp;ldquo;Machine Learning&amp;rdquo;, &amp;ldquo;Computer Vision&amp;rdquo;, &amp;ldquo;Artifical Intelligence&amp;rdquo; and &amp;ldquo;Robotics&amp;rdquo; and there was imbalance in the classes.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Writing A Scikit Learn Compatible Clustering Algorithm</title>
      <link>http://localhost:1313/posts/kmeans/</link>
      <pubDate>Wed, 04 May 2022 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/posts/kmeans/</guid>
      <description>&lt;h2 id=&#34;contents&#34;&gt;&#xA;  Contents&#xA;  &lt;a class=&#34;heading-link&#34; href=&#34;#contents&#34;&gt;&#xA;    &lt;i class=&#34;fa-solid fa-link&#34; aria-hidden=&#34;true&#34; title=&#34;Link to heading&#34;&gt;&lt;/i&gt;&#xA;    &lt;span class=&#34;sr-only&#34;&gt;Link to heading&lt;/span&gt;&#xA;  &lt;/a&gt;&#xA;&lt;/h2&gt;&#xA;&lt;hr&gt;&#xA;&lt;p&gt;&lt;strong&gt;&lt;a href=&#34;#first-bullet&#34; &gt;1. Introduction&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt;&#xA;&lt;p&gt;&lt;strong&gt;&lt;a href=&#34;#second-bullet&#34; &gt;2. The k-means clustering alogorithm&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt;&#xA;&lt;p&gt;&lt;strong&gt;&lt;a href=&#34;#third-bullet&#34; &gt;3. Writing the k-means algorithm with NumPy&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt;&#xA;&lt;p&gt;&lt;strong&gt;&lt;a href=&#34;#fourth-bullet&#34; &gt;4. Writing a Scikit-Learn compatible estimator&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt;&#xA;&lt;p&gt;&lt;strong&gt;&lt;a href=&#34;#fifth-bullet&#34; &gt;5. Using the elbow method and Pipelines&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt;&#xA;&lt;p&gt;&lt;strong&gt;&lt;a href=&#34;#sixth-bullet&#34; &gt;6. Summary &amp;amp; References&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt;&#xA;&lt;h2 id=&#34;introduction&#34;&gt;&#xA;  Introduction &lt;a class=&#34;anchor&#34; id=&#34;first-bullet&#34;&gt;&lt;/a&gt;&#xA;  &lt;a class=&#34;heading-link&#34; href=&#34;#introduction&#34;&gt;&#xA;    &lt;i class=&#34;fa-solid fa-link&#34; aria-hidden=&#34;true&#34; title=&#34;Link to heading&#34;&gt;&lt;/i&gt;&#xA;    &lt;span class=&#34;sr-only&#34;&gt;Link to heading&lt;/span&gt;&#xA;  &lt;/a&gt;&#xA;&lt;/h2&gt;&#xA;&lt;hr&gt;&#xA;&lt;p&gt;Clustering algorithms and unsupervised learning methods have been gaining popularity recently. This is partly because the amount of data being generated has increased exponentially, but also because labels for this data are often still hard to come by. Labeling data can be time consuming and requires human effort which can be expensive. Unsupervised learning methods are machine learning methods that can be used to gleam information from unlabeled data. Clustering algorithms specifically take unlabeled points within a dataset and try to group them into &amp;ldquo;clusters&amp;rdquo;. Within clusters datapoints are very &amp;ldquo;similar&amp;rdquo; (in some sense that will be discussed later) and datapoints between cluster are very &amp;ldquo;disimilar&amp;rdquo;.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Frequentist &amp; Bayesian Statistics With Py4J &amp; PyMC3</title>
      <link>http://localhost:1313/posts/bayesmle/</link>
      <pubDate>Tue, 04 May 2021 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/posts/bayesmle/</guid>
      <description>&lt;h2 id=&#34;contents&#34;&gt;&#xA;  Contents&#xA;  &lt;a class=&#34;heading-link&#34; href=&#34;#contents&#34;&gt;&#xA;    &lt;i class=&#34;fa-solid fa-link&#34; aria-hidden=&#34;true&#34; title=&#34;Link to heading&#34;&gt;&lt;/i&gt;&#xA;    &lt;span class=&#34;sr-only&#34;&gt;Link to heading&lt;/span&gt;&#xA;  &lt;/a&gt;&#xA;&lt;/h2&gt;&#xA;&lt;hr&gt;&#xA;&lt;p&gt;&lt;strong&gt;&lt;a href=&#34;#first-bullet&#34; &gt;1. Introduction&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt;&#xA;&lt;p&gt;&lt;strong&gt;&lt;a href=&#34;#second-bullet&#34; &gt;2. Sampling A Distribution Written In Scala Using Py4J&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt;&#xA;&lt;p&gt;&lt;strong&gt;&lt;a href=&#34;#third-bullet&#34; &gt;3. The Maximum Likelihood Estimator&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt;&#xA;&lt;p&gt;&lt;strong&gt;&lt;a href=&#34;#fourth-bullet&#34; &gt;4. Confidence Intervals From Fisher Information&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt;&#xA;&lt;p&gt;&lt;strong&gt;&lt;a href=&#34;#fifth-bullet&#34; &gt;5. Bayesian Esimatators &amp;amp; Credible Intervals With PyMC3&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt;&#xA;&lt;p&gt;&lt;strong&gt;&lt;a href=&#34;#sixth-bullet&#34; &gt;6. Connecting The Two Methods&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt;&#xA;&lt;p&gt;&lt;strong&gt;&lt;a href=&#34;#seventh-bullet&#34; &gt;7. Conclusions&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt;&#xA;&lt;h2 id=&#34;1-introduction&#34;&gt;&#xA;  1. Introduction &lt;a class=&#34;anchor&#34; id=&#34;first-bullet&#34;&gt;&lt;/a&gt;&#xA;  &lt;a class=&#34;heading-link&#34; href=&#34;#1-introduction&#34;&gt;&#xA;    &lt;i class=&#34;fa-solid fa-link&#34; aria-hidden=&#34;true&#34; title=&#34;Link to heading&#34;&gt;&lt;/i&gt;&#xA;    &lt;span class=&#34;sr-only&#34;&gt;Link to heading&lt;/span&gt;&#xA;  &lt;/a&gt;&#xA;&lt;/h2&gt;&#xA;&lt;hr&gt;&#xA;&lt;p&gt;In this post I want to go back to the basics of statistics, but with an advanced spin on things. By &amp;ldquo;advanced spin&amp;rdquo; I mean, both from in terms of mathematics and computational techniques. The topic I&amp;rsquo;ll dive into is:&lt;/p&gt;</description>
    </item>
    <item>
      <title>Text Classification 3: A Machine Learning Powered Web App</title>
      <link>http://localhost:1313/posts/nlp3/</link>
      <pubDate>Sat, 31 Oct 2020 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/posts/nlp3/</guid>
      <description>&lt;h2 id=&#34;contents&#34;&gt;&#xA;  Contents&#xA;  &lt;a class=&#34;heading-link&#34; href=&#34;#contents&#34;&gt;&#xA;    &lt;i class=&#34;fa-solid fa-link&#34; aria-hidden=&#34;true&#34; title=&#34;Link to heading&#34;&gt;&lt;/i&gt;&#xA;    &lt;span class=&#34;sr-only&#34;&gt;Link to heading&lt;/span&gt;&#xA;  &lt;/a&gt;&#xA;&lt;/h2&gt;&#xA;&lt;hr&gt;&#xA;&lt;p&gt;&lt;strong&gt;&lt;a href=&#34;#first-bullet&#34; &gt;1. Introduction&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt;&#xA;&lt;p&gt;&lt;strong&gt;&lt;a href=&#34;#second-bullet&#34; &gt;2. Converting A Model To A Rest API With FastAPI&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt;&#xA;&lt;p&gt;&lt;strong&gt;&lt;a href=&#34;#third-bullet&#34; &gt;3. Building A Web App With FastAPI &amp;amp; Bootstrap&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt;&#xA;&lt;p&gt;&lt;strong&gt;&lt;a href=&#34;#fourth-bullet&#34; &gt;4. Deploying The App With Docker &amp;amp; Google Cloud Run&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt;&#xA;&lt;p&gt;&lt;strong&gt;&lt;a href=&#34;#fifth-bullet&#34; &gt;5. Conclusions&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt;&#xA;&lt;hr&gt;&#xA;&lt;h2 id=&#34;introduction&#34;&gt;&#xA;  Introduction &lt;a class=&#34;anchor&#34; id=&#34;first-bullet&#34;&gt;&lt;/a&gt;&#xA;  &lt;a class=&#34;heading-link&#34; href=&#34;#introduction&#34;&gt;&#xA;    &lt;i class=&#34;fa-solid fa-link&#34; aria-hidden=&#34;true&#34; title=&#34;Link to heading&#34;&gt;&lt;/i&gt;&#xA;    &lt;span class=&#34;sr-only&#34;&gt;Link to heading&lt;/span&gt;&#xA;  &lt;/a&gt;&#xA;&lt;/h2&gt;&#xA;&lt;hr&gt;&#xA;&lt;p&gt;In the last &lt;a href=&#34;http://michael-harmon.com/blog/NLP2.html&#34;  class=&#34;external-link&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;blogpost&lt;/a&gt; we covered building a text classification using &lt;a href=&#34;http://scikit-learn.org/&#34;&gt;Scikit-learn&lt;/a&gt; and using the &lt;a href=&#34;https://www.nltk.org/&#34;  class=&#34;external-link&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Natural Language Toolkit (NLTK)&lt;/a&gt;. We used a weighted Support Vector Machine to handle the imbalance of the classes in the datset. Once we trained our model we then serialized the Scikit-learn pipeline using &lt;a href=&#34;https://joblib.readthedocs.io/en/latest/&#34;  class=&#34;external-link&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Joblib&lt;/a&gt;.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Green Buildings 3: Build &amp; Deploy Models With MLflow &amp; Docker</title>
      <link>http://localhost:1313/posts/greenbuildings3/</link>
      <pubDate>Thu, 23 Apr 2020 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/posts/greenbuildings3/</guid>
      <description>&lt;h2 id=&#34;contents&#34;&gt;&#xA;  Contents&#xA;  &lt;a class=&#34;heading-link&#34; href=&#34;#contents&#34;&gt;&#xA;    &lt;i class=&#34;fa-solid fa-link&#34; aria-hidden=&#34;true&#34; title=&#34;Link to heading&#34;&gt;&lt;/i&gt;&#xA;    &lt;span class=&#34;sr-only&#34;&gt;Link to heading&lt;/span&gt;&#xA;  &lt;/a&gt;&#xA;&lt;/h2&gt;&#xA;&lt;hr&gt;&#xA;&lt;p&gt;&lt;strong&gt;&lt;a href=&#34;#intro&#34; &gt;1. Introduction&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt;&#xA;&lt;p&gt;&lt;strong&gt;&lt;a href=&#34;#mlflow-one&#34; &gt;2. Intro To MLflow&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt;&#xA;&lt;p&gt;&lt;strong&gt;&lt;a href=&#34;#mlflow-two&#34; &gt;3. Linear Regression &amp;amp; Logging A Simple Run&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt;&#xA;&lt;p&gt;&lt;strong&gt;&lt;a href=&#34;#mlflow-three&#34; &gt;4. XGBoost &amp;amp; Logging Nested Runs for GridSearchCV&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt;&#xA;&lt;p&gt;&lt;strong&gt;&lt;a href=&#34;#mlflow-four&#34; &gt;5. MLflow Models: Model Serving With REST APIs&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt;&#xA;&lt;p&gt;&lt;strong&gt;&lt;a href=&#34;#mlflow-five&#34; &gt;6. Deploying to Google App Engine with Docker&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt;&#xA;&lt;p&gt;&lt;strong&gt;&lt;a href=&#34;#fifth-bullet&#34; &gt;7. Conclusions &lt;/a&gt;&lt;/strong&gt;&lt;/p&gt;&#xA;&lt;hr&gt;&#xA;&lt;h2 id=&#34;introduction&#34;&gt;&#xA;  Introduction &lt;a class=&#34;anchor&#34; id=&#34;intro&#34;&gt;&lt;/a&gt;&#xA;  &lt;a class=&#34;heading-link&#34; href=&#34;#introduction&#34;&gt;&#xA;    &lt;i class=&#34;fa-solid fa-link&#34; aria-hidden=&#34;true&#34; title=&#34;Link to heading&#34;&gt;&lt;/i&gt;&#xA;    &lt;span class=&#34;sr-only&#34;&gt;Link to heading&lt;/span&gt;&#xA;  &lt;/a&gt;&#xA;&lt;/h2&gt;&#xA;&lt;hr&gt;&#xA;&lt;p&gt;This is the third and final post in a series of blog posts about energy usage and green house gas emissions of buildings in New York City. In the &lt;a href=&#34;http://michael-harmon.com/posts/greenbuildings1/&#34;  class=&#34;external-link&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;first post&lt;/a&gt; I covered exploratory data analysis and outlier removal.  In the &lt;a href=&#34;http://michael-harmon.com/posts/greenbuildings2/&#34;  class=&#34;external-link&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;second post&lt;/a&gt; I covered imputing missing values. These topics make up the majority of what is called &amp;ldquo;data cleaning&amp;rdquo;.  This last post will deal with model building and model deployment. Specifically I will build a model of New York City building green house gas emissions based on the building energy usage metrics. After I build a sufficiently accurate model I will convert the model to &lt;a href=&#34;https://restfulapi.net/&#34;  class=&#34;external-link&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;REST API&lt;/a&gt; for serving and then deploy the REST API to the cloud.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Green Buildings 2: Imputing Missing Values With Scikit-Learn</title>
      <link>http://localhost:1313/posts/greenbuildings2/</link>
      <pubDate>Sun, 16 Feb 2020 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/posts/greenbuildings2/</guid>
      <description>&lt;h2 id=&#34;contents&#34;&gt;&#xA;  Contents&#xA;  &lt;a class=&#34;heading-link&#34; href=&#34;#contents&#34;&gt;&#xA;    &lt;i class=&#34;fa-solid fa-link&#34; aria-hidden=&#34;true&#34; title=&#34;Link to heading&#34;&gt;&lt;/i&gt;&#xA;    &lt;span class=&#34;sr-only&#34;&gt;Link to heading&lt;/span&gt;&#xA;  &lt;/a&gt;&#xA;&lt;/h2&gt;&#xA;&lt;hr&gt;&#xA;&lt;p&gt;&lt;strong&gt;&lt;a href=&#34;#first-bullet&#34; &gt;1. Introduction&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt;&#xA;&lt;p&gt;&lt;strong&gt;&lt;a href=&#34;#second-bullet&#34; &gt;2. Analyzing Distributions &amp;amp; Correlations&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt;&#xA;&lt;p&gt;&lt;strong&gt;&lt;a href=&#34;#third-bullet&#34; &gt;3. Imputing Missing Values With Scikit-Learn &lt;/a&gt;&lt;/strong&gt;&lt;/p&gt;&#xA;&lt;p&gt;&lt;strong&gt;&lt;a href=&#34;#fourth-bullet&#34; &gt;4. Next Steps&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt;&#xA;&lt;h2 id=&#34;introduction&#34;&gt;&#xA;  Introduction &lt;a class=&#34;anchor&#34; id=&#34;first-bullet&#34;&gt;&lt;/a&gt;&#xA;  &lt;a class=&#34;heading-link&#34; href=&#34;#introduction&#34;&gt;&#xA;    &lt;i class=&#34;fa-solid fa-link&#34; aria-hidden=&#34;true&#34; title=&#34;Link to heading&#34;&gt;&lt;/i&gt;&#xA;    &lt;span class=&#34;sr-only&#34;&gt;Link to heading&lt;/span&gt;&#xA;  &lt;/a&gt;&#xA;&lt;/h2&gt;&#xA;&lt;hr&gt;&#xA;&lt;p&gt;This is the second post in a series of blog posts about building a predictive model of green house gas emissions of buildings in NYC. In my &lt;a href=&#34;http://michael-harmon.com/posts/greenbuildings1&#34;  class=&#34;external-link&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;first post&lt;/a&gt; I covered how to perform&lt;/p&gt;</description>
    </item>
    <item>
      <title>Text Classification 1: Imbalanced Data</title>
      <link>http://localhost:1313/posts/nlp1/</link>
      <pubDate>Wed, 01 Jan 2020 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/posts/nlp1/</guid>
      <description>&lt;h2 id=&#34;contents&#34;&gt;&#xA;  Contents&#xA;  &lt;a class=&#34;heading-link&#34; href=&#34;#contents&#34;&gt;&#xA;    &lt;i class=&#34;fa-solid fa-link&#34; aria-hidden=&#34;true&#34; title=&#34;Link to heading&#34;&gt;&lt;/i&gt;&#xA;    &lt;span class=&#34;sr-only&#34;&gt;Link to heading&lt;/span&gt;&#xA;  &lt;/a&gt;&#xA;&lt;/h2&gt;&#xA;&lt;p&gt;&lt;strong&gt;&lt;a href=&#34;#first-bullet&#34; &gt;1. Introduction&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt;&#xA;&lt;p&gt;&lt;strong&gt;&lt;a href=&#34;#second-bullet&#34; &gt;2. The Dataset: Creating, Storing and Exploring&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt;&#xA;&lt;p&gt;&lt;strong&gt;&lt;a href=&#34;#third-bullet&#34; &gt;3. TF-IDF: Preprocessing &amp;amp; Feature Extraction&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt;&#xA;&lt;p&gt;&lt;strong&gt;&lt;a href=&#34;#fourth-bullet&#34; &gt;4. The Naive Bayes Model&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt;&#xA;&lt;p&gt;&lt;strong&gt;&lt;a href=&#34;#fifth-bullet&#34; &gt;5. Imablanced Learn: Fixing Imbalanced Data&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt;&#xA;&lt;p&gt;&lt;strong&gt;&lt;a href=&#34;#sixth-bullet&#34; &gt;6. Weighted Support Vector Machines &lt;/a&gt;&lt;/strong&gt;&lt;/p&gt;&#xA;&lt;p&gt;&lt;strong&gt;&lt;a href=&#34;#seventh-bullet&#34; &gt;9. Next Steps&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt;&#xA;&lt;hr&gt;&#xA;&lt;h2 id=&#34;introduction&#34;&gt;&#xA;  Introduction &lt;a class=&#34;anchor&#34; id=&#34;first-bullet&#34;&gt;&lt;/a&gt;&#xA;  &lt;a class=&#34;heading-link&#34; href=&#34;#introduction&#34;&gt;&#xA;    &lt;i class=&#34;fa-solid fa-link&#34; aria-hidden=&#34;true&#34; title=&#34;Link to heading&#34;&gt;&lt;/i&gt;&#xA;    &lt;span class=&#34;sr-only&#34;&gt;Link to heading&lt;/span&gt;&#xA;  &lt;/a&gt;&#xA;&lt;/h2&gt;&#xA;&lt;hr&gt;&#xA;&lt;p&gt;Natural language processing (NLP) is an hot topic in data science and machine learning.  While research in NLP dates back to the 1950&amp;rsquo;s, the real revolution in this domain came in 1980&amp;rsquo;s and 1990&amp;rsquo;s with the introduction of statistical models and fast computing. Before this most language processing tasks made use of hand-coded rules which were generally not very robust.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Numerical Linear Algebra In Machine Learning</title>
      <link>http://localhost:1313/posts/numlinalg/</link>
      <pubDate>Wed, 11 Dec 2019 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/posts/numlinalg/</guid>
      <description>&lt;h2 id=&#34;contents&#34;&gt;&#xA;  Contents&#xA;  &lt;a class=&#34;heading-link&#34; href=&#34;#contents&#34;&gt;&#xA;    &lt;i class=&#34;fa-solid fa-link&#34; aria-hidden=&#34;true&#34; title=&#34;Link to heading&#34;&gt;&lt;/i&gt;&#xA;    &lt;span class=&#34;sr-only&#34;&gt;Link to heading&lt;/span&gt;&#xA;  &lt;/a&gt;&#xA;&lt;/h2&gt;&#xA;&lt;hr&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;Introduction&lt;/p&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;Introduction To Function Approximation&lt;/p&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;Introduction To Regression&lt;/p&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;Linear Solvers For Least Squares Regression&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;Cholesky Factorization For Normal Equations&lt;/p&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;Singular Values Decomposition&lt;/p&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;Controlling For Overfitting With Regularization&lt;/p&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;Implementation in Scikit-learn&lt;/p&gt;&#xA;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;A Touch Of Recommendation Systems&lt;/p&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;Where To Go From Here&lt;/p&gt;&#xA;&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;h2 id=&#34;introduction&#34;&gt;&#xA;  Introduction&#xA;  &lt;a class=&#34;heading-link&#34; href=&#34;#introduction&#34;&gt;&#xA;    &lt;i class=&#34;fa-solid fa-link&#34; aria-hidden=&#34;true&#34; title=&#34;Link to heading&#34;&gt;&lt;/i&gt;&#xA;    &lt;span class=&#34;sr-only&#34;&gt;Link to heading&lt;/span&gt;&#xA;  &lt;/a&gt;&#xA;&lt;/h2&gt;&#xA;&lt;hr&gt;&#xA;&lt;p&gt;In this blogpost we&amp;rsquo;ll go over applications of numerical linear algebra in machine learning starting out with regression and ending with modern recommender systems! Numerical linear algebra (and numerical analysis more generally) was one of thoses courses that I learned, thought was boring and never wanted to study again. Only with maturity that comes with age (and a PhD) was I able to understand and appreciate the true power of numerical linear alebra.  Infact &lt;em&gt;understanding (distribued) linear algebra is probably one of the most important and useful tools I have ever learned.&lt;/em&gt;  It has allowed me to contribute to open source libraries for scientific computing and understand how big data and machine learning systems work.  The reason why numerical linear algebra is so important is because it allows us to approximate functions.  In scientific computing and machine learning one is interested in &lt;strong&gt;how to approximate a function&lt;/strong&gt; &lt;span class=&#34;katex&#34;&gt;&lt;math xmlns=&#34;http://www.w3.org/1998/Math/MathML&#34;&gt;&lt;semantics&gt;&lt;mrow&gt;&lt;mi&gt;f&lt;/mi&gt;&lt;mo stretchy=&#34;false&#34;&gt;(&lt;/mo&gt;&lt;mi&gt;x&lt;/mi&gt;&lt;mo stretchy=&#34;false&#34;&gt;)&lt;/mo&gt;&lt;/mrow&gt;&lt;annotation encoding=&#34;application/x-tex&#34;&gt;f(x)&lt;/annotation&gt;&lt;/semantics&gt;&lt;/math&gt;&lt;/span&gt;&#xA;.  Numerical analysis and statistics concerns itself with &lt;strong&gt;how good is our approximation to&lt;/strong&gt; &lt;span class=&#34;katex&#34;&gt;&lt;math xmlns=&#34;http://www.w3.org/1998/Math/MathML&#34;&gt;&lt;semantics&gt;&lt;mrow&gt;&lt;mi&gt;f&lt;/mi&gt;&lt;mo stretchy=&#34;false&#34;&gt;(&lt;/mo&gt;&lt;mi&gt;x&lt;/mi&gt;&lt;mo stretchy=&#34;false&#34;&gt;)&lt;/mo&gt;&lt;/mrow&gt;&lt;annotation encoding=&#34;application/x-tex&#34;&gt;f(x)&lt;/annotation&gt;&lt;/semantics&gt;&lt;/math&gt;&lt;/span&gt;&#xA;?&lt;/p&gt;</description>
    </item>
    <item>
      <title>Green Buildings 1: Exploratory Analysis &amp; Outlier Removal</title>
      <link>http://localhost:1313/posts/greenbuildings1/</link>
      <pubDate>Sat, 12 May 2018 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/posts/greenbuildings1/</guid>
      <description>&lt;h1 id=&#34;&#34;&gt;&#xA;  &#xA;  &lt;a class=&#34;heading-link&#34; href=&#34;#&#34;&gt;&#xA;    &lt;i class=&#34;fa-solid fa-link&#34; aria-hidden=&#34;true&#34; title=&#34;Link to heading&#34;&gt;&lt;/i&gt;&#xA;    &lt;span class=&#34;sr-only&#34;&gt;Link to heading&lt;/span&gt;&#xA;  &lt;/a&gt;&#xA;&lt;/h1&gt;&#xA;&lt;h2 id=&#34;content&#34;&gt;&#xA;  Content&#xA;  &lt;a class=&#34;heading-link&#34; href=&#34;#content&#34;&gt;&#xA;    &lt;i class=&#34;fa-solid fa-link&#34; aria-hidden=&#34;true&#34; title=&#34;Link to heading&#34;&gt;&lt;/i&gt;&#xA;    &lt;span class=&#34;sr-only&#34;&gt;Link to heading&lt;/span&gt;&#xA;  &lt;/a&gt;&#xA;&lt;/h2&gt;&#xA;&lt;hr&gt;&#xA;&lt;p&gt;&lt;strong&gt;&lt;a href=&#34;#first-bullet&#34; &gt;1. Introduction&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt;&#xA;&lt;p&gt;&lt;strong&gt;&lt;a href=&#34;#second-bullet&#34; &gt;2. Exploratory Data Analysis&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt;&#xA;&lt;p&gt;&lt;strong&gt;&lt;a href=&#34;#third-bullet&#34; &gt;3. Connecting To BigQuery&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt;&#xA;&lt;p&gt;&lt;strong&gt;&lt;a href=&#34;#fourth-bullet&#34; &gt;4. Removing Visual Outliers&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt;&#xA;&lt;p&gt;&lt;strong&gt;&lt;a href=&#34;#fifth-bullet&#34; &gt;5. Removing Outliers With Isolation Forests&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt;&#xA;&lt;p&gt;&lt;strong&gt;&lt;a href=&#34;#sixth-bullet&#34; &gt;6. Recomendations &amp;amp; Next Steps&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt;&#xA;&lt;h2 id=&#34;introduction&#34;&gt;&#xA;  Introduction &lt;a class=&#34;anchor&#34; id=&#34;first-bullet&#34;&gt;&lt;/a&gt;&#xA;  &lt;a class=&#34;heading-link&#34; href=&#34;#introduction&#34;&gt;&#xA;    &lt;i class=&#34;fa-solid fa-link&#34; aria-hidden=&#34;true&#34; title=&#34;Link to heading&#34;&gt;&lt;/i&gt;&#xA;    &lt;span class=&#34;sr-only&#34;&gt;Link to heading&lt;/span&gt;&#xA;  &lt;/a&gt;&#xA;&lt;/h2&gt;&#xA;&lt;hr&gt;&#xA;&lt;p&gt;I started this project a while back with a goal of taking the 2016 NYC Benchmarking Law building energy usage data and do something interesting with it. I originally attmpted to clean and analyze this data set to try to find ways to reduce builings&amp;rsquo; energy usage and subsequently their green house gas emissions. After a few iterations I thought it might be interesting to see if I could predict the emission of green house gases from buildings by looking at their age, energy and water consumption as well as other energy consumption metrics. This is somewhat of a difficult task as the data was very messy and in this first blogpost I will cover how to perform,&lt;/p&gt;</description>
    </item>
    <item>
      <title>SQL Wars: Comparing Relational Databases</title>
      <link>http://localhost:1313/posts/sqlwars/</link>
      <pubDate>Thu, 13 Apr 2017 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/posts/sqlwars/</guid>
      <description>&lt;h2 id=&#34;contents&#34;&gt;&#xA;  Contents&#xA;  &lt;a class=&#34;heading-link&#34; href=&#34;#contents&#34;&gt;&#xA;    &lt;i class=&#34;fa-solid fa-link&#34; aria-hidden=&#34;true&#34; title=&#34;Link to heading&#34;&gt;&lt;/i&gt;&#xA;    &lt;span class=&#34;sr-only&#34;&gt;Link to heading&lt;/span&gt;&#xA;  &lt;/a&gt;&#xA;&lt;/h2&gt;&#xA;&lt;hr&gt;&#xA;&lt;p&gt;&lt;strong&gt;&lt;a href=&#34;#Introduction&#34; &gt;1. Introduction&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt;&#xA;&lt;p&gt;&lt;strong&gt;&lt;a href=&#34;#Preliminaries&#34; &gt;2. Preliminary Ideas&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt;&#xA;&lt;p&gt;&lt;strong&gt;&lt;a href=&#34;#SQLite&#34; &gt;3. C.R.U.D. with SQLite&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt;&#xA;&lt;p&gt;&lt;strong&gt;&lt;a href=&#34;#PostgreSQL&#34; &gt;4. C.R.U.D. with PostgreSQL&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt;&#xA;&lt;p&gt;&lt;strong&gt;&lt;a href=&#34;#Conclusion&#34; &gt;5. Conclusion&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt;&#xA;&lt;hr&gt;&#xA;&lt;h2 id=&#34;introduction&#34;&gt;&#xA;  Introduction&#xA;  &lt;a class=&#34;heading-link&#34; href=&#34;#introduction&#34;&gt;&#xA;    &lt;i class=&#34;fa-solid fa-link&#34; aria-hidden=&#34;true&#34; title=&#34;Link to heading&#34;&gt;&lt;/i&gt;&#xA;    &lt;span class=&#34;sr-only&#34;&gt;Link to heading&lt;/span&gt;&#xA;  &lt;/a&gt;&#xA;&lt;/h2&gt;&#xA;&lt;hr&gt;&#xA;&lt;p&gt;Coming from a computational science/applied mathematics background many of the ideas of data science/machine learning are second nature to me. One thing that was very new to me was creating and manipulating databases. In computational science we don&amp;rsquo;t really deal with databases and I/O is something to avoid as much as possible because it limits performance.  Therefore, in this blog post I&amp;rsquo;ll be going what I have learned about SQL databases, i.e. what they are, how to set them up, and how to use them.&lt;/p&gt;</description>
    </item>
    <item>
      <title></title>
      <link>http://localhost:1313/about/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/about/</guid>
      <description>&lt;h2 id=&#34;about-me&#34;&gt;&#xA;  About Me&#xA;  &lt;a class=&#34;heading-link&#34; href=&#34;#about-me&#34;&gt;&#xA;    &lt;i class=&#34;fa-solid fa-link&#34; aria-hidden=&#34;true&#34; title=&#34;Link to heading&#34;&gt;&lt;/i&gt;&#xA;    &lt;span class=&#34;sr-only&#34;&gt;Link to heading&lt;/span&gt;&#xA;  &lt;/a&gt;&#xA;&lt;/h2&gt;&#xA;&lt;hr&gt;&#xA;&lt;p&gt;I&amp;rsquo;m a AI/ML Engineer and Data Scientist based in New York City, with 10 years of experience solving complex business and technical problems through data. I specialize in end-to-end development of scalable machine learning solutions, and have worked on and led cross-functional teams with projects spanning supervised/unsupervised learning, AutoML, optimization, entity resolution, natural language processing, geospatial analysis, econometrics, marketing analytics and generative artificial intelligence (GenAI).&#xA;&lt;/br&gt;&#xA;&lt;/br&gt;&#xA;Since 2017, I’ve been working extensively with &lt;a href=&#34;https://spark.apache.org/&#34;&gt;Apache Spark&lt;/a&gt; in both Python and Scala, building high-performance data pipelines and distributed systems, leading to two patents. More recently, I’ve been focused on building applications powered by GenAI and large language models (LLMs), with a strong interest in &lt;a href=&#34;https://www.langchain.com/&#34;&gt;LangChain&lt;/a&gt; and &lt;a href=&#34;https://www.langchain.com/langgraph&#34;&gt;LangGraph&lt;/a&gt; frameworks. I lead with a blend of hands-on technical skill and strategic vision—driven by a passion for technology, a commitment to team growth, and a focus on solving complex problems with real-world impact.&#xA;&lt;/br&gt;&#xA;&lt;/br&gt;&#xA;With a &lt;a href=&#34;https://repositories.lib.utexas.edu/server/api/core/bitstreams/ee56a75d-c4e1-4b65-83b7-5ab8e7de9ddc/content&#34;&gt;PhD in Computational Applied Mathematics&lt;/a&gt; from the &lt;a href=&#34;https://oden.utexas.edu/&#34;&gt;University of Texas at Austin&lt;/a&gt; I have a strong background in both quantitative methods and scientific software engineering. My focus during graduate school was on researching &lt;a href=&#34;https://en.wikipedia.org/wiki/Discontinuous_Galerkin_method&#34;&gt;discontinuous Galerkin methods&lt;/a&gt; and &lt;a href=&#34;https://en.wikipedia.org/wiki/Finite_element_method&#34;&gt;finite element methods&lt;/a&gt; for simulating &lt;a href=&#34;https://en.wikipedia.org/wiki/Photoelectrochemical_cell&#34;&gt;photo-electrochemical solar cells&lt;/a&gt; which led me to contribute multiple times to the open source finite element library, &lt;a href=&#34;https://www.dealii.org/&#34;&gt;deal.ii&lt;/a&gt;.&#xA;&lt;/br&gt;&#xA;&lt;/br&gt;&#xA;In my free time, I proudly serve in the &lt;a href=&#34;https://cgaux.org/about.php&#34;&gt;U.S. Coast Guard Auxiliary&lt;/a&gt;, the uniformed volunteer component of the United States Coast Guard.&#xA;&lt;/br&gt;&#xA;&lt;/br&gt;&#xA;In another life, I was a competitive athlete and coach in Brazilian Jiu Jitsu for over 17 years. During my career I trained with and competed against the best fighters all over the world. In 2012, I won the World Championships and in 2015 achieved the rank of 1st degree Black Belt from 2x Pan American Champion &lt;a href=&#34;https://www.ginsbergacademy.com/&#34;&gt;Professor Dave Ginsberg&lt;/a&gt;. I also had the privlage of coaching hundreds of students and I am proud to have created local, national and world champions. Despite having to stop training, I am grateful for the all experiences and to have had an amazing coach along with great mentors, sponsors, friends, teammates and students.&lt;/p&gt;</description>
    </item>
    <item>
      <title></title>
      <link>http://localhost:1313/projects/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/projects/</guid>
      <description>&lt;h2 id=&#34;web-applications&#34;&gt;&#xA;  Web Applications&#xA;  &lt;a class=&#34;heading-link&#34; href=&#34;#web-applications&#34;&gt;&#xA;    &lt;i class=&#34;fa-solid fa-link&#34; aria-hidden=&#34;true&#34; title=&#34;Link to heading&#34;&gt;&lt;/i&gt;&#xA;    &lt;span class=&#34;sr-only&#34;&gt;Link to heading&lt;/span&gt;&#xA;  &lt;/a&gt;&#xA;&lt;/h2&gt;&#xA;&lt;hr&gt;&#xA;&lt;p&gt;These are full blow web applications that I have deployed on &lt;a href=&#34;https://cloud.google.com&#34;  class=&#34;external-link&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Google Cloud Platform&lt;/a&gt;&lt;/p&gt;&#xA;&lt;center&gt;&#xA;&lt;a href=&#34;https://github.com/mdh266/rag-jfk&#34;&gt;&#xA;&lt;span class=&#34;fa-stack fa-4x&#34;&gt; &#xA;&lt;i class=&#34;fa fa-circle fa-stack-2x&#34;&gt;&lt;/i&gt;&#xA;&lt;i class=&#34;fas fa-flag-usa fa-stack-1x fa-inverse&#34;&gt;&lt;/i&gt;&#xA;&lt;/span&gt;&#xA;&lt;h5&gt;Retrivial Augmented Generation on JFK Speeches&lt;/h5&gt;&#xA;&lt;/a&gt;&#xA;&lt;/br&gt;&#xA;&lt;a href=&#34;https://github.com/mdh266/speech2image&#34;&gt;&#xA;&lt;span class=&#34;fa-stack fa-4x&#34;&gt; &#xA;&lt;i class=&#34;fa fa-circle fa-stack-2x&#34;&gt;&lt;/i&gt;&#xA;&lt;i class=&#34;fas fa-microphone fa-stack-1x fa-inverse&#34;&gt;&lt;/i&gt;&#xA;&lt;/span&gt;&#xA;&lt;h5&gt;&#xA;A Serverless Speech-To-Image App&#xA;&lt;/h5&gt;&#xA;&lt;/a&gt;&#xA;&lt;/br&gt;&#xA;&lt;a href=&#34;https://github.com/mdh266/speech-chatbot&#34;&gt;&#xA;&lt;span class=&#34;fa-stack fa-4x&#34;&gt; &#xA;&lt;i class=&#34;fa fa-circle fa-stack-2x&#34;&gt;&lt;/i&gt;&#xA;&lt;i class=&#34;fa fa-language fa-stack-1x fa-inverse&#34;&#34;&gt;&lt;/i&gt;&#xA;&lt;/span&gt;&#xA;&lt;h5&gt;&#xA;    &lt;strong&gt;A Multimodal, Multi-Lingual ChatBot&lt;/strong&gt;&#xA;&lt;/h5&gt;&#xA;&lt;/a&gt;&#xA;&lt;/br&gt;&#xA;&lt;a href=&#34;https://docwebapp-j3zdo3lhcq-uc.a.run.app&#34;&gt;&#xA;&lt;span class=&#34;fa-stack fa-4x&#34;&gt; &#xA;&lt;i class=&#34;fa fa-circle fa-stack-2x&#34;&gt;&lt;/i&gt;&#xA;&lt;i class=&#34;fas fa-newspaper fa-stack-1x fa-inverse&#34;&gt;&lt;/i&gt;&#xA;&lt;/span&gt;&#xA;&lt;h5&gt;&#xA;    &lt;strong&gt;A Serverless Document Classifier App&lt;/strong&gt;&#xA;&lt;/h5&gt;&#xA;&lt;/a&gt;&#xA;&lt;/br&gt;&#xA;&lt;a href=&#34;http://michael-harmon.com/CrimeTime/&#34;&gt;&#xA;&lt;span class=&#34;fa-stack fa-4x&#34;&gt;&#xA;&lt;i class=&#34;fa fa-circle fa-stack-2x&#34;&gt;&lt;/i&gt;&#xA;&lt;i class=&#34;fa fa-user-secret fa-stack-1x fa-inverse&#34;&gt;&lt;/i&gt;&#xA;&lt;/span&gt;&#xA;&lt;h5&gt;&#xA;&lt;strong&gt;CrimeTime: Predicting crime rates in NYC&lt;/strong&gt;&#xA;&lt;/h5&gt;&#xA;&lt;/a&gt;&#xA;&lt;/center&gt;&#xA;&lt;/br&gt;&#xA;&lt;/br&gt;&#xA;&lt;/br&gt;&#xA;&lt;h2 id=&#34;open-source-software--libraries&#34;&gt;&#xA;  Open Source Software &amp;amp; Libraries&#xA;  &lt;a class=&#34;heading-link&#34; href=&#34;#open-source-software--libraries&#34;&gt;&#xA;    &lt;i class=&#34;fa-solid fa-link&#34; aria-hidden=&#34;true&#34; title=&#34;Link to heading&#34;&gt;&lt;/i&gt;&#xA;    &lt;span class=&#34;sr-only&#34;&gt;Link to heading&lt;/span&gt;&#xA;  &lt;/a&gt;&#xA;&lt;/h2&gt;&#xA;&lt;hr&gt;&#xA;&lt;p&gt;These are libraries that I have either authored or been a contributor.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Contact Me</title>
      <link>http://localhost:1313/contact/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/contact/</guid>
      <description>&lt;p&gt;Follow me on GitHub &lt;a href=&#34;https://github.com/mdh266/&#34;  class=&#34;external-link&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;@mdh266&lt;/a&gt;&lt;/p&gt;&#xA;&lt;p&gt;Connect with me on &lt;a href=&#34;https://www.linkedin.com/in/michaeldavidharmon/&#34;  class=&#34;external-link&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;LinkedIn&lt;/a&gt;&lt;/p&gt;&#xA;&lt;p&gt;&lt;strong&gt;Email me:&lt;/strong&gt; &lt;a href=&#34;mailto:mdh266@gmail.com&#34; &gt;mdh266@gmail.com&lt;/a&gt;&lt;/p&gt;</description>
    </item>
  </channel>
</rss>
